{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b87c2f1-bf27-424d-a81c-7f87fb6bf852",
    "_uuid": "80cc4c11-2dae-4dd0-b9af-744f0a3ca78f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:12.496445Z",
     "iopub.status.busy": "2024-12-09T15:04:12.496227Z",
     "iopub.status.idle": "2024-12-09T15:04:17.036254Z",
     "shell.execute_reply": "2024-12-09T15:04:17.035331Z",
     "shell.execute_reply.started": "2024-12-09T15:04:12.496420Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "Path.ls = lambda x: list(x.iterdir())\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8cf82a6-8db1-4290-8394-361eea7adfb5",
    "_uuid": "d708d474-010a-4058-afdf-a481afdba41f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:27.889627Z",
     "iopub.status.busy": "2024-12-09T15:04:27.888750Z",
     "iopub.status.idle": "2024-12-09T15:04:31.184033Z",
     "shell.execute_reply": "2024-12-09T15:04:31.183129Z",
     "shell.execute_reply.started": "2024-12-09T15:04:27.889590Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "from fastai.vision.models.unet import DynamicUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48aa4fe5-57ec-4653-91cd-baf117d8eb93",
    "_uuid": "93b0ae7c-7efa-4f2e-b971-81595aa734fd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:32.973841Z",
     "iopub.status.busy": "2024-12-09T15:04:32.973173Z",
     "iopub.status.idle": "2024-12-09T15:04:36.649574Z",
     "shell.execute_reply": "2024-12-09T15:04:36.648518Z",
     "shell.execute_reply.started": "2024-12-09T15:04:32.973791Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the training data\n",
    "color_path = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train'\n",
    "\n",
    "# Get all class directories\n",
    "class_dirs = [d for d in os.listdir(color_path) if os.path.isdir(os.path.join(color_path, d))]\n",
    "\n",
    "max_images = 10000\n",
    "all_images = []\n",
    "np.random.seed(100)\n",
    "\n",
    "# Gather up to 1000 images total\n",
    "for class_dir in class_dirs:\n",
    "    if len(all_images) >= max_images:\n",
    "        break\n",
    "    class_path_pattern = os.path.join(color_path, class_dir, '*.JPEG')\n",
    "    class_images = glob.glob(class_path_pattern)\n",
    "    np.random.shuffle(class_images)  # Shuffle to get a random sample from this class\n",
    "    needed = max_images - len(all_images)\n",
    "    to_add = class_images[:needed]\n",
    "    all_images.extend(to_add)\n",
    "\n",
    "print(\"Total images collected:\", len(all_images))\n",
    "\n",
    "# Split into training and validation sets (80% train, 20% val)\n",
    "train_paths, val_paths = train_test_split(all_images, test_size=0.2, random_state=123)\n",
    "\n",
    "print(\"Total training images:\", len(train_paths))\n",
    "print(\"Total validation images:\", len(val_paths))\n",
    "\n",
    "# Display a few training images\n",
    "_, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "for ax, img_path in zip(axes.flatten(), train_paths[:16]):\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45912ef0-ab41-46ce-97d0-60a5df43ec8b",
    "_uuid": "f2cc7f72-5070-47c4-8a98-f1ef2cb202b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:36.652210Z",
     "iopub.status.busy": "2024-12-09T15:04:36.651927Z",
     "iopub.status.idle": "2024-12-09T15:04:37.983304Z",
     "shell.execute_reply": "2024-12-09T15:04:37.982139Z",
     "shell.execute_reply.started": "2024-12-09T15:04:36.652183Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), Image.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Resize((SIZE, SIZE), Image.BICUBIC)\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\")\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...] / 50. - 1.\n",
    "        ab = img_lab[[1, 2], ...] / 110.\n",
    "        return {'L': L, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloaders(paths, split='train', batch_size=16, n_workers=4, pin_memory=True):\n",
    "    dataset = ColorizationDataset(paths, split=split)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            num_workers=n_workers, pin_memory=pin_memory, shuffle=(split=='train'))\n",
    "    return dataloader\n",
    "\n",
    "train_dl = make_dataloaders(train_paths, split='train', batch_size=16)\n",
    "val_dl = make_dataloaders(val_paths, split='val', batch_size=16)\n",
    "\n",
    "data = next(iter(train_dl))\n",
    "Ls, abs_ = data['L'], data['ab']\n",
    "print(\"Train batch shapes:\", Ls.shape, abs_.shape)\n",
    "print(\"Number of batches:\", len(train_dl), \"train,\", len(val_dl), \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05b831c8-451a-4f66-8f55-7b4a3ef94f13",
    "_uuid": "e3cf192c-1eee-4c5f-8700-8d894fcec0c4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:37.985746Z",
     "iopub.status.busy": "2024-12-09T15:04:37.985356Z",
     "iopub.status.idle": "2024-12-09T15:04:38.007343Z",
     "shell.execute_reply": "2024-12-09T15:04:38.006141Z",
     "shell.execute_reply.started": "2024-12-09T15:04:37.985708Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_c is None: input_c = nf\n",
    "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "        \n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters * 8\n",
    "        for _ in range(3):\n",
    "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                  for i in range(n_down)]\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "12722a80-5547-4ba8-aa6a-de4512e12a3f",
    "_uuid": "3e4ac061-eee9-4c41-baae-58a43b6b690f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.010146Z",
     "iopub.status.busy": "2024-12-09T15:04:38.009743Z",
     "iopub.status.idle": "2024-12-09T15:04:38.026154Z",
     "shell.execute_reply": "2024-12-09T15:04:38.025410Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.010098Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiscaleUnet(nn.Module):\n",
    "    def __init__(self, input_c=3, output_c=2, n_down=8, num_filters=64):\n",
    "        super().__init__()\n",
    "        self.unet = Unet(input_c=input_c, output_c=output_c, n_down=n_down, num_filters=num_filters)\n",
    "\n",
    "    def forward(self, L):\n",
    "        # Generate multiscale inputs\n",
    "        L_low = nn.functional.interpolate(L, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "        L_high = nn.functional.interpolate(L, scale_factor=2.0, mode='bilinear', align_corners=False)\n",
    "        conditional_input = torch.cat((L, L_low, L_high), dim=1)  # Concatenate original, low, and high-res inputs\n",
    "        return self.unet(conditional_input)\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, height, width = x.size()\n",
    "        query = self.query(x).view(batch, -1, width * height).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch, -1, width * height)\n",
    "        attention = torch.bmm(query, key)\n",
    "        attention = nn.functional.softmax(attention, dim=-1)\n",
    "        value = self.value(x).view(batch, -1, width * height)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1)).view(batch, channels, height, width)\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class ConditionalUnetWithFeatures(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64, feature_dim=512):\n",
    "        super().__init__()\n",
    "        # ResNet for feature extraction\n",
    "        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n",
    "        self.feature_extractor.fc = nn.Identity()  # Remove classification head\n",
    "        self.feature_extractor.eval()\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Generator with multiscale inputs\n",
    "        self.unet = MultiscaleUnet(input_c=input_c + 3, output_c=output_c, n_down=n_down, num_filters=num_filters)\n",
    "\n",
    "    def forward(self, L):\n",
    "        # Extract semantic features\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(L.repeat(1, 3, 1, 1))  # Pass grayscale image through ResNet\n",
    "        features = features.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, SIZE, SIZE)  # Reshape to spatial dimensions\n",
    "        conditional_input = torch.cat((L, features), dim=1)  # Concatenate grayscale and features\n",
    "        return self.unet(conditional_input)\n",
    "\n",
    "class ConditionalDiscriminatorWithFeatures(PatchDiscriminator):\n",
    "    def __init__(self, input_c=3, feature_dim=512, num_filters=64, n_down=3):\n",
    "        super().__init__(input_c + feature_dim // 64, num_filters, n_down)\n",
    "        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n",
    "        self.feature_extractor.fc = nn.Identity()\n",
    "        self.feature_extractor.eval()\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, L):\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(L.repeat(1, 3, 1, 1))\n",
    "        features = features.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, SIZE, SIZE)\n",
    "        conditional_input = torch.cat((x, features), dim=1)  # Concatenate image and features\n",
    "        return super().forward(conditional_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83174253-ff82-416d-adc0-4bf7883c185b",
    "_uuid": "36d84b62-a4d5-43c2-9856-0ee244079585",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.027698Z",
     "iopub.status.busy": "2024-12-09T15:04:38.027371Z",
     "iopub.status.idle": "2024-12-09T15:04:38.044864Z",
     "shell.execute_reply": "2024-12-09T15:04:38.043995Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.027660Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "    \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "    \n",
    "    def forward(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss\n",
    "\n",
    "def init_weights(net, init='norm', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def create_loss_meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "    \n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a013c520-b5a2-4d61-b575-6e290f291311",
    "_uuid": "482fbde6-c946-4b1e-96a9-9f79387fdc6e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.046284Z",
     "iopub.status.busy": "2024-12-09T15:04:38.045979Z",
     "iopub.status.idle": "2024-12-09T15:04:38.057521Z",
     "shell.execute_reply": "2024-12-09T15:04:38.056727Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.046258Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab):\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "    \n",
    "def visualize(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    real_imgs = lab_to_rgb(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 12))  # Adjusted height for row titles\n",
    "    rows, cols = 3, 5  # 3 rows (Grayscale, Model generated, Actual), up to 5 columns\n",
    "\n",
    "    # Add row titles\n",
    "    plt.subplot(rows, cols, 1).set_title(\"Grayscale Image\", fontsize=16, loc='left')\n",
    "    plt.subplot(rows, cols, cols + 1).set_title(\"Model Generated Image\", fontsize=16, loc='left')\n",
    "    plt.subplot(rows, cols, 2 * cols + 1).set_title(\"Actual Image\", fontsize=16, loc='left')\n",
    "\n",
    "    for i in range(min(5, L.size(0))):\n",
    "        # Grayscale Image (Row 1)\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Model Generated Image (Row 2)\n",
    "        ax = plt.subplot(rows, cols, i + 1 + cols)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Actual Image (Row 3)\n",
    "        ax = plt.subplot(rows, cols, i + 1 + 2 * cols)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"images_new/colorization_{time.time()}.png\")\n",
    "\n",
    "def log_results(loss_meter_dict, log_file, epoch, iteration):\n",
    "    \"\"\"\n",
    "    Log the training results to a CSV file and print them to the console.\n",
    "    \"\"\"\n",
    "    with open(log_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for loss_name, loss_meter in loss_meter_dict.items():\n",
    "            print(f\"{loss_name}: {loss_meter.avg:.5f}\")  # Print to console\n",
    "            # Append the results to the CSV file\n",
    "            writer.writerow([epoch, iteration, loss_name, loss_meter.avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3802f4e6-4e76-4aa9-ad73-840ebabe331a",
    "_uuid": "67e89719-ea16-42ff-8186-2caf71a15602",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.058862Z",
     "iopub.status.busy": "2024-12-09T15:04:38.058585Z",
     "iopub.status.idle": "2024-12-09T15:04:38.306639Z",
     "shell.execute_reply": "2024-12-09T15:04:38.305708Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.058809Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionalGANModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        # Initialize or use the provided generator\n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        \n",
    "        # Initialize the discriminator with conditioning\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        \n",
    "        # Define losses\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        \n",
    "        # Optimizers for generator and discriminator\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "    \n",
    "    def backward_D(self):\n",
    "        # Concatenate grayscale input (L) with fake/generated colors\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        \n",
    "        # Concatenate grayscale input (L) with real colors\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        \n",
    "        # L1 loss between the generated and actual colors\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        \n",
    "        # Total generator loss\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        # Update discriminator\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        # Update generator\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80da6339-55d8-446a-bc69-7e7010517e62",
    "_uuid": "86523ef7-8658-4282-88a3-02b7f5b00892",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.308132Z",
     "iopub.status.busy": "2024-12-09T15:04:38.307796Z",
     "iopub.status.idle": "2024-12-09T15:04:38.319926Z",
     "shell.execute_reply": "2024-12-09T15:04:38.319080Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.308106Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Ensure DataLoader tensors are on the correct device\n",
    "def move_batch_to_device(batch, device):\n",
    "    return {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "import random\n",
    "def train_model(model, train_dl, epochs, display_every=200, log_file=\"logs_training_final.csv\"):\n",
    "    # Prepare the CSV file for logging\n",
    "    with open(log_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header\n",
    "        writer.writerow([\"Epoch\", \"Iteration\", \"Loss Name\", \"Average Loss\"])\n",
    "\n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = create_loss_meters()\n",
    "        i = 0\n",
    "        # Generate a random interval for image visualization for this epoch\n",
    "        visualize_every = random.randint(150, 499)\n",
    "        for batch_data in tqdm(train_dl):\n",
    "            model.setup_input(batch_data)\n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=batch_data['L'].size(0))\n",
    "            i += 1\n",
    "\n",
    "            # Log results at fixed intervals\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_results(loss_meter_dict, log_file, epoch=e + 1, iteration=i)\n",
    "\n",
    "            # Visualize images at random intervals\n",
    "            if i % visualize_every == 0:\n",
    "                print(f\"Visualizing at random iteration {i} (interval: {visualize_every})\")\n",
    "                # Fetch a new batch of validation data for visualization\n",
    "                data = next(iter(val_dl))\n",
    "                visualize(model, data, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0750fe81-2ef6-45bf-aa5c-54d921bd3a9c",
    "_uuid": "5fe6aaab-e80c-41b6-a8bf-757310e8da4b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:38.321424Z",
     "iopub.status.busy": "2024-12-09T15:04:38.321102Z",
     "iopub.status.idle": "2024-12-09T15:04:38.333659Z",
     "shell.execute_reply": "2024-12-09T15:04:38.332795Z",
     "shell.execute_reply.started": "2024-12-09T15:04:38.321386Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # First, instantiate the resnet18 model with pretrained weights\n",
    "    backbone = resnet18(pretrained=True)\n",
    "    # Now pass this instantiated model to create_body\n",
    "    body = create_body(backbone, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
    "    return net_G\n",
    "\n",
    "\n",
    "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
    "    for e in range(epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        for batch_data in tqdm(train_dl):\n",
    "            L, ab = batch_data['L'].to(device), batch_data['ab'].to(device)\n",
    "            preds = net_G(L)\n",
    "            loss = criterion(preds, ab)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            loss_meter.update(loss.item(), L.size(0))\n",
    "            \n",
    "        print(f\"Epoch {e + 1}/{epochs}\")\n",
    "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fac7d474-9b13-4d3b-85ff-1df6d975aea1",
    "_uuid": "7e79e250-5100-4849-b3e2-d427ca97ce0b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T14:57:56.186345Z",
     "iopub.status.busy": "2024-12-09T14:57:56.186066Z",
     "iopub.status.idle": "2024-12-09T14:57:56.202028Z",
     "shell.execute_reply": "2024-12-09T14:57:56.201155Z",
     "shell.execute_reply.started": "2024-12-09T14:57:56.186321Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Pretrain the generator\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "opt_g = optim.Adam(net_G.parameters(), lr=1e-4)\n",
    "criterion_L1 = nn.L1Loss()\n",
    "\n",
    "print(\"Pretraining the generator with L1 loss...\")\n",
    "pretrain_generator(net_G, train_dl, opt_g, criterion_L1, epochs=20)\n",
    "\n",
    "# Save the pretrained generator weights\n",
    "torch.save(net_G.state_dict(), \"res18-unet-v2.pt\")\n",
    "print(\"Pretraining complete and weights saved.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d3d42b7-5036-4246-ad24-e8ab8b84f88b",
    "_uuid": "67e5e654-f7bd-4c0a-904f-9dbeefb2c042",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T15:04:55.447405Z",
     "iopub.status.busy": "2024-12-09T15:04:55.447054Z",
     "iopub.status.idle": "2024-12-09T15:04:58.226573Z",
     "shell.execute_reply": "2024-12-09T15:04:58.225612Z",
     "shell.execute_reply.started": "2024-12-09T15:04:55.447374Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to the pretrained weights\n",
    "pretrained_weights_path = \"/kaggle/input/model-dl-novel/other/default/1/res18-unet-v2.pt\"  # Update this path if the weights are saved elsewhere\n",
    "\n",
    "# Load the pretrained generator\n",
    "print(\"Loading pretrained generator weights...\")\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Build the generator architecture\n",
    "net_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))  # Load weights\n",
    "net_G = net_G.to(device)  # Move the model to the appropriate device (GPU/CPU)\n",
    "net_G.eval()  # Set the model to evaluation mode (optional, for inference)\n",
    "\n",
    "print(\"Pretrained generator loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3501ceb9-3127-4fc6-ade9-cd87df049dbd",
    "_uuid": "217a3d98-d429-4842-a173-2879da620dda",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T16:04:37.050610Z",
     "iopub.status.busy": "2024-12-09T16:04:37.050260Z",
     "iopub.status.idle": "2024-12-09T16:04:41.175525Z",
     "shell.execute_reply": "2024-12-09T16:04:41.174347Z",
     "shell.execute_reply.started": "2024-12-09T16:04:37.050578Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "# Ensure the images directory exists\n",
    "#os.makedirs(\"/kaggle/working/images\", exist_ok=True)\n",
    "#!rm /kaggle/working/images/colorization_1733694174.787311.png\n",
    "!mv images_new images_old_3\n",
    "!mkdir images_new\n",
    "!rm logs_training_final.csv\n",
    "!rm state.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b822f864-aa28-4336-8784-4673b2236acb",
    "_uuid": "dc7b8faa-e835-4f6d-aca9-8307719f739a",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-09T11:07:43.858130Z",
     "iopub.status.idle": "2024-12-09T11:07:43.858428Z",
     "shell.execute_reply": "2024-12-09T11:07:43.858301Z",
     "shell.execute_reply.started": "2024-12-09T11:07:43.858286Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load the pretrained generator from the working directory\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "\n",
    "# Ensure the model is on the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net_G = net_G.to(device)\n",
    "\n",
    "# Load the pretrained weights into the generator\n",
    "pretrained_weights_path = \"/kaggle/input/res18-v2/other/default/1/res18-unet-v2.pt\"  # Path to the weights file\n",
    "net_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
    "print(\"Pretrained weights loaded into the generator.\")\n",
    "\n",
    "# Create the main model with the pretrained net_G\n",
    "model = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\n",
    "model = model.to(device)  # Ensure the full model is on the GPU\n",
    "print(\"Main model created and moved to the GPU (if available).\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the full model (GAN + L1) now...\")\n",
    "train_model(model, train_dl, epochs=50, display_every=200)\n",
    "print(\"Training complete.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d19dcb0-80ed-4e29-825f-e809020e24c5",
    "_uuid": "f79fedda-ea50-4283-8d7b-34cd0307d6fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T16:04:51.362519Z",
     "iopub.status.busy": "2024-12-09T16:04:51.361759Z",
     "iopub.status.idle": "2024-12-09T19:26:52.137875Z",
     "shell.execute_reply": "2024-12-09T19:26:52.136749Z",
     "shell.execute_reply.started": "2024-12-09T16:04:51.362481Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained generator\n",
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "net_G.load_state_dict(torch.load(\"/kaggle/working/res18-unet-v2.pt\", map_location=device))\n",
    "\n",
    "# Create the main model with the pretrained net_G\n",
    "model = ConditionalGANModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\n",
    "print(\"Training the full model (GAN + L1) now...\")\n",
    "train_model(model, train_dl, epochs=50, display_every=200)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1e9fbec-6f8b-4055-bcbb-ce5a724b76c9",
    "_uuid": "b9aa31fe-724e-4d44-b89f-b22677fd8309",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "493a5096-aed5-4be9-95cb-7865d2754a57",
    "_uuid": "3005f8c5-8e6f-45cd-b086-da9d781ef5fd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T19:47:03.680419Z",
     "iopub.status.busy": "2024-12-09T19:47:03.679593Z",
     "iopub.status.idle": "2024-12-09T19:47:37.701541Z",
     "shell.execute_reply": "2024-12-09T19:47:37.700099Z",
     "shell.execute_reply.started": "2024-12-09T19:47:03.680385Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb\n",
    "\n",
    "# Convert LAB to RGB\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Convert L and ab channels to RGB images.\n",
    "    Args:\n",
    "        L: Lightness channel (normalized to [-1, 1])\n",
    "        ab: Color channels (normalized to [-1, 1])\n",
    "    Returns:\n",
    "        List of RGB images.\n",
    "    \"\"\"\n",
    "    L = (L + 1.) * 50.  # Rescale L to [0, 100]\n",
    "    ab = ab * 110.      # Rescale ab to [-110, 110]\n",
    "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
    "    return [lab2rgb(img) for img in Lab]\n",
    "\n",
    "# Metrics Calculation\n",
    "def calculate_metrics(real, pred):\n",
    "    \"\"\"\n",
    "    Calculate MSE, PSNR, and SSIM for the given images.\n",
    "    Args:\n",
    "        real: Ground truth image (RGB).\n",
    "        pred: Predicted image (RGB).\n",
    "    Returns:\n",
    "        mse, psnr_value, ssim_value\n",
    "    \"\"\"\n",
    "    mse = np.mean((real - pred) ** 2)\n",
    "    psnr_value = psnr(real, pred, data_range=1.0)  # Normalize to [0, 1]\n",
    "\n",
    "    # Dynamically adjust `win_size` for SSIM\n",
    "    min_dim = min(real.shape[0], real.shape[1])\n",
    "    if min_dim < 7:\n",
    "        ssim_value = 0.0  # Skip SSIM calculation for very small images\n",
    "    else:\n",
    "        win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)  # Ensure odd value for `win_size`\n",
    "        win_size = max(3, win_size)  # Ensure win_size is at least 3\n",
    "        try:\n",
    "            ssim_value = ssim(real, pred, data_range=1.0, channel_axis=-1, win_size=win_size)\n",
    "        except ValueError as e:\n",
    "            print(f\"SSIM calculation failed: {e}. Skipping this image.\")\n",
    "            ssim_value = 0.0\n",
    "\n",
    "    return mse, psnr_value, ssim_value\n",
    "\n",
    "# Plot Results\n",
    "def plot_results(real_imgs, grayscale_imgs, pred_imgs):\n",
    "    \"\"\"\n",
    "    Display original, grayscale, and generated images.\n",
    "    Args:\n",
    "        real_imgs: List of ground truth RGB images.\n",
    "        grayscale_imgs: List of grayscale input images.\n",
    "        pred_imgs: List of predicted RGB images.\n",
    "    \"\"\"\n",
    "    num_images = min(len(real_imgs), len(grayscale_imgs), len(pred_imgs))\n",
    "    plt.figure(figsize=(15, 5 * num_images))\n",
    "    for i in range(num_images):\n",
    "        # Ground Truth\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow(real_imgs[i])\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Grayscale Input\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow(grayscale_imgs[i][0], cmap=\"gray\")\n",
    "        plt.title(\"Grayscale Input\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Predicted\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow(pred_imgs[i])\n",
    "        plt.title(\"Generated\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_and_plot(model, val_dl, num_images_to_plot=50):\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation data and plot results for the first few images.\n",
    "    Args:\n",
    "        model: Trained model.\n",
    "        val_dl: Validation DataLoader.\n",
    "        num_images_to_plot: Number of images to display.\n",
    "    Returns:\n",
    "        Average metrics (MSE, PSNR, SSIM) over the entire validation dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = []\n",
    "    real_imgs, grayscale_imgs, pred_imgs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            L = data['L'].to(device)  # Grayscale input\n",
    "            ab_real = data['ab'].to(device)  # Ground truth color channels\n",
    "\n",
    "            # Generate predictions\n",
    "            ab_pred = model.net_G(L)\n",
    "\n",
    "            # Convert predictions and ground truth to RGB\n",
    "            real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
    "            pred_rgb = lab_to_rgb(L.cpu().numpy(), ab_pred.cpu().numpy())\n",
    "\n",
    "            # Calculate metrics for all images in this batch\n",
    "            for real, pred in zip(real_rgb, pred_rgb):\n",
    "                mse, psnr_value, ssim_value = calculate_metrics(real, pred)\n",
    "                results.append([mse, psnr_value, ssim_value])\n",
    "\n",
    "            # Collect images for plotting\n",
    "            if len(real_imgs) < num_images_to_plot:\n",
    "                real_imgs.extend(real_rgb)\n",
    "                grayscale_imgs.extend(data['L'].cpu().numpy())\n",
    "                pred_imgs.extend(pred_rgb)\n",
    "\n",
    "            # Stop collecting images for plotting once enough are collected\n",
    "            if len(real_imgs) >= num_images_to_plot:\n",
    "                real_imgs = real_imgs[:num_images_to_plot]\n",
    "                grayscale_imgs = grayscale_imgs[:num_images_to_plot]\n",
    "                pred_imgs = pred_imgs[:num_images_to_plot]\n",
    "                break\n",
    "\n",
    "    # Plot the first few images\n",
    "    plot_results(real_imgs, grayscale_imgs, pred_imgs)\n",
    "\n",
    "    # Calculate and print average metrics\n",
    "    results = np.array(results)\n",
    "    avg_metrics = np.mean(results, axis=0)\n",
    "    print(len(results))\n",
    "    print(f\"Average Metrics: MSE={avg_metrics[0]:.4f}, PSNR={avg_metrics[1]:.2f} dB, SSIM={avg_metrics[2]:.4f}\")\n",
    "    return avg_metrics\n",
    "\n",
    "# Example Usage\n",
    "evaluate_and_plot(model, val_dl, num_images_to_plot=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:10:32.765357Z",
     "iopub.status.busy": "2024-12-09T20:10:32.764584Z",
     "iopub.status.idle": "2024-12-09T20:11:39.474784Z",
     "shell.execute_reply": "2024-12-09T20:11:39.473496Z",
     "shell.execute_reply.started": "2024-12-09T20:10:32.765318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.color import lab2rgb\n",
    "from torchvision.models import inception_v3\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "\n",
    "# Function to convert LAB to RGB\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Convert LAB image to RGB image.\n",
    "    \"\"\"\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
    "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
    "    return np.stack(rgb_imgs)\n",
    "\n",
    "# Function to calculate MSE, PSNR, and SSIM\n",
    "def calculate_metrics(color, predicted):\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics: MSE, PSNR, and SSIM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mse = np.mean((color - predicted) ** 2)\n",
    "        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "        min_dim = min(color.shape[0], color.shape[1])\n",
    "\n",
    "        # Dynamically set `win_size` or skip SSIM if the image is too small\n",
    "        if min_dim < 7:\n",
    "            print(f\"Skipping SSIM for image with insufficient dimensions: {color.shape}\")\n",
    "            ssim_value = 0.0\n",
    "        else:\n",
    "            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n",
    "            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n",
    "\n",
    "        return mse, psnr, ssim_value\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "        return float('inf'), float('inf'), 0.0\n",
    "\n",
    "# FID Feature Extraction\n",
    "def extract_features(images, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extract features from images using a pretrained Inception model.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    model.eval()\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)\n",
    "        batch = (batch - 0.5) * 2  # Normalize to [-1, 1] as expected by InceptionV3\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "            pred = adaptive_avg_pool2d(pred, (1, 1))  # Pool to 1x1\n",
    "        features.append(pred.cpu().numpy().squeeze())\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "# FID Calculation\n",
    "def calculate_fid(real_features, fake_features):\n",
    "    \"\"\"\n",
    "    Calculate FID between real and fake features.\n",
    "    \"\"\"\n",
    "    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n",
    "    diff = mu1 - mu2\n",
    "    covmean = np.linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return fid\n",
    "\n",
    "# Evaluation over the validation dataset\n",
    "def evaluate_model_full(model, val_dl):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the entire validation dataset and compute MSE, PSNR, SSIM, and FID.\n",
    "    \"\"\"\n",
    "    results = []  # Store MSE, PSNR, SSIM for all images\n",
    "    real_images, pred_images = [], []  # Store real and predicted images for FID computation\n",
    "\n",
    "    # Load InceptionV3 model for FID\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.fc = torch.nn.Identity()  # Remove the classification head\n",
    "\n",
    "    for i, data in enumerate(val_dl):\n",
    "        L = data['L'].to(device)\n",
    "        ab_real = data['ab'].to(device)\n",
    "\n",
    "        # Predict color channels\n",
    "        with torch.no_grad():\n",
    "            ab_predicted = model.net_G(L).cpu().numpy()\n",
    "\n",
    "        # Convert LAB to RGB\n",
    "        real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
    "        pred_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n",
    "\n",
    "        # Store images for FID computation\n",
    "        real_images.extend(real_rgb)\n",
    "        pred_images.extend(pred_rgb)\n",
    "\n",
    "        # Calculate metrics for all images in this batch\n",
    "        for real, pred in zip(real_rgb, pred_rgb):\n",
    "            mse, psnr_value, ssim_value = calculate_metrics(real, pred)\n",
    "            results.append([mse, psnr_value, ssim_value])\n",
    "\n",
    "    # Calculate FID\n",
    "    real_features = extract_features(real_images, inception_model)\n",
    "    pred_features = extract_features(pred_images, inception_model)\n",
    "    fid_value = calculate_fid(real_features, pred_features)\n",
    "\n",
    "    # Calculate average metrics\n",
    "    results = np.array(results)\n",
    "    avg_metrics = np.mean(results, axis=0)\n",
    "    print(f\"Average Metrics over Validation Set: MSE={avg_metrics[0]:.4f}, \"\n",
    "          f\"PSNR={avg_metrics[1]:.2f} dB, SSIM={avg_metrics[2]:.4f}, FID={fid_value:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model_full(model, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:13:25.431632Z",
     "iopub.status.busy": "2024-12-09T20:13:25.431259Z",
     "iopub.status.idle": "2024-12-09T20:14:29.938596Z",
     "shell.execute_reply": "2024-12-09T20:14:29.937761Z",
     "shell.execute_reply.started": "2024-12-09T20:13:25.431599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display a single image comparison\n",
    "def display_prediction(real_img, grayscale_img, predicted_img, mse, psnr, ssim_value, rank):\n",
    "    \"\"\"\n",
    "    Display the ground truth, grayscale input, and predicted image with metrics.\n",
    "    Args:\n",
    "        real_img: The ground truth image in RGB.\n",
    "        grayscale_img: The grayscale input image.\n",
    "        predicted_img: The predicted image in RGB.\n",
    "        mse: Mean Squared Error.\n",
    "        psnr: Peak Signal-to-Noise Ratio.\n",
    "        ssim_value: Structural Similarity Index.\n",
    "        rank: The rank of the image in the sorted results.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Ground Truth Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(real_img)\n",
    "    plt.title(\"Ground Truth\", fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Grayscale Input Image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(grayscale_img, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale Input\", fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Predicted Image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_img)\n",
    "    plt.title(f\"Prediction\\nMSE: {mse:.4f}, PSNR: {psnr:.2f}, SSIM: {ssim_value:.4f}\", fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Rank: {rank}\", fontsize=16, color=\"blue\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display Top 15 Images\n",
    "def display_top_15_images(results, val_dl, model):\n",
    "    \"\"\"\n",
    "    Display the top 15 ranked images based on MSE (ascending), PSNR (descending), and SSIM (descending).\n",
    "    Args:\n",
    "        results: List of metrics for each image.\n",
    "        val_dl: Validation DataLoader.\n",
    "        model: Trained model.\n",
    "    \"\"\"\n",
    "    # Sort results by MSE (ascending), PSNR (descending), SSIM (descending)\n",
    "    sorted_results = sorted(\n",
    "        enumerate(results),  # Include the index to identify which image\n",
    "        key=lambda x: (x[1][0], -x[1][1], -x[1][2])  # Sort by MSE (low), then PSNR (high), then SSIM (high)\n",
    "    )\n",
    "\n",
    "    # Extract the top 15 results\n",
    "    top_15_results = sorted_results[:100]\n",
    "\n",
    "    # Display each of the top 15 images\n",
    "    for rank, (index, metrics) in enumerate(top_15_results, start=1):\n",
    "        mse, psnr_value, ssim_value = metrics\n",
    "\n",
    "        # Retrieve the real image, grayscale input, and predicted image\n",
    "        L = val_dl.dataset[index][\"L\"].numpy()  # Grayscale input (normalized)\n",
    "        ab_real = val_dl.dataset[index][\"ab\"].numpy()  # Ground truth color\n",
    "        ab_predicted = model.net_G(torch.tensor(L).unsqueeze(0).to(device)).cpu().detach().numpy().squeeze()\n",
    "\n",
    "        # Convert LAB to RGB\n",
    "        real_img = lab_to_rgb(L[np.newaxis, ...], ab_real[np.newaxis, ...])[0]\n",
    "        predicted_img = lab_to_rgb(L[np.newaxis, ...], ab_predicted[np.newaxis, ...])[0]\n",
    "        grayscale_img = L[0]  # Grayscale image for visualization\n",
    "\n",
    "        # Display the image with metrics\n",
    "        display_prediction(real_img, grayscale_img, predicted_img, mse, psnr_value, ssim_value, rank)\n",
    "\n",
    "# Call the function to display the top 15 images\n",
    "display_top_15_images(results, val_dl, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T20:15:55.800425Z",
     "iopub.status.busy": "2024-12-09T20:15:55.799755Z",
     "iopub.status.idle": "2024-12-09T20:23:23.177478Z",
     "shell.execute_reply": "2024-12-09T20:23:23.176561Z",
     "shell.execute_reply.started": "2024-12-09T20:15:55.800390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.color import lab2rgb\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.transforms import Resize\n",
    "import warnings\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the generator model\n",
    "def load_model(generator_path, device):\n",
    "    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n",
    "    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n",
    "    net_G.eval()  # Set to evaluation mode\n",
    "    return net_G.to(device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator_path = \"/kaggle/working/net_G_final.pt\"\n",
    "generator = load_model(generator_path, device)\n",
    "\n",
    "# Convert LAB to RGB\n",
    "def lab_to_rgb(L, ab):\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
    "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
    "    return np.stack(rgb_imgs)\n",
    "\n",
    "# FID Calculation\n",
    "def calculate_fid(real_features, fake_features):\n",
    "    mu1 = np.mean(real_features, axis=0)\n",
    "    sigma1 = np.cov(real_features, rowvar=False)\n",
    "    mu2 = np.mean(fake_features, axis=0)\n",
    "    sigma2 = np.cov(fake_features, rowvar=False)\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
    "\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    fid = np.sum(diff ** 2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "    return fid\n",
    "\n",
    "# Feature Extraction for FID\n",
    "def extract_features(images, model, batch_size=32):\n",
    "    features = []\n",
    "    transform = Resize((224, 224))  # ResNet50 expects (224, 224) inputs\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)\n",
    "        batch = transform(batch)  # Resize to (224, 224)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "        features.append(pred.cpu().numpy())\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "# Metrics Calculation\n",
    "def calculate_metrics(color, predicted):\n",
    "    mse = np.mean((color - predicted) ** 2)\n",
    "    psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "    min_dim = min(color.shape[0], color.shape[1])\n",
    "    ssim_value = 0.0 if min_dim < 7 else ssim(color, predicted, data_range=1.0, channel_axis=-1)\n",
    "    return mse, psnr, ssim_value\n",
    "\n",
    "# Load ResNet50 for FID\n",
    "resnet_model = resnet50(pretrained=True).to(device)\n",
    "resnet_model.eval()\n",
    "\n",
    "# Evaluation Loop\n",
    "results, real_features, fake_features = [], [], []\n",
    "\n",
    "for data in val_dl:\n",
    "    L = data['L'].to(device)\n",
    "    ab_real = data['ab'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ab_predicted = generator(L).cpu().numpy()\n",
    "\n",
    "    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
    "    pred_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n",
    "\n",
    "    real_features.extend(real_rgb)\n",
    "    fake_features.extend(pred_rgb)\n",
    "\n",
    "    for real, pred in zip(real_rgb, pred_rgb):\n",
    "        mse, psnr, ssim_value = calculate_metrics(real, pred)\n",
    "        results.append([mse, psnr, ssim_value])\n",
    "\n",
    "# FID Calculation\n",
    "real_features = extract_features(real_features, resnet_model)\n",
    "fake_features = extract_features(fake_features, resnet_model)\n",
    "fid_value = calculate_fid(real_features, fake_features)\n",
    "\n",
    "# Add FID to results\n",
    "results = [result + [fid_value] for result in results]\n",
    "\n",
    "# Calculate average metrics\n",
    "average_metrics = np.mean(results, axis=0)\n",
    "print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, \"\n",
    "      f\"SSIM={average_metrics[2]:.4f}, FID={average_metrics[3]:.4f}\")\n",
    "\n",
    "# Plot Metrics\n",
    "def plot_metric(metric_values, metric_name):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(metric_values, label=metric_name)\n",
    "    plt.xlabel(\"Image Index\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"{metric_name} Across Validation Images\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Extract individual metrics\n",
    "all_mse = [result[0] for result in results]\n",
    "all_psnr = [result[1] for result in results]\n",
    "all_ssim = [result[2] for result in results]\n",
    "\n",
    "# Plot individual metrics\n",
    "plot_metric(all_mse, \"MSE\")\n",
    "plot_metric(all_psnr, \"PSNR (dB)\")\n",
    "plot_metric(all_ssim, \"SSIM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49ed43ac-1f32-45d3-9532-96735efc23fe",
    "_uuid": "45debb1c-568e-45c1-a909-0c565031240e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-09T19:26:52.140000Z",
     "iopub.status.busy": "2024-12-09T19:26:52.139682Z",
     "iopub.status.idle": "2024-12-09T19:26:52.851622Z",
     "shell.execute_reply": "2024-12-09T19:26:52.850783Z",
     "shell.execute_reply.started": "2024-12-09T19:26:52.139969Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the generator weights\n",
    "generator_save_path = \"/kaggle/working/net_G_final.pt\"\n",
    "torch.save(model.net_G.state_dict(), generator_save_path)\n",
    "print(f\"Generator weights saved to {generator_save_path}\")\n",
    "\n",
    "# Save the entire model\n",
    "main_model_save_path = \"/kaggle/working/main_model_final.pt\"\n",
    "torch.save({\n",
    "    'net_G': model.net_G.state_dict(),\n",
    "    'net_D': model.net_D.state_dict(),\n",
    "    'opt_G': model.opt_G.state_dict(),\n",
    "    'opt_D': model.opt_D.state_dict()\n",
    "}, main_model_save_path)\n",
    "print(f\"Full model saved to {main_model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0dbb3dd9-4070-4be4-b6e8-a30d2fd12add",
    "_uuid": "5970fbf8-2994-431d-af6b-f36205a50fef",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d80c0184-d186-4ea0-a69c-d26f440f4ad8",
    "_uuid": "5e849670-8eda-42ca-a1c5-4992f817f07b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00b20a07-57fb-4010-bfb8-5b11df3b4e58",
    "_uuid": "07cbc419-c4ab-4660-8a7d-acc0be39b253",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "578e2927-e8ac-48dd-9e31-39574b62a117",
    "_uuid": "85581794-3a20-4b54-9026-987e3dab058a",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-09T16:00:44.591143Z",
     "iopub.status.idle": "2024-12-09T16:00:44.591418Z",
     "shell.execute_reply": "2024-12-09T16:00:44.591300Z",
     "shell.execute_reply.started": "2024-12-09T16:00:44.591285Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import lab2rgb\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Convert L and ab channels to RGB images.\n",
    "    Args:\n",
    "        L: Lightness channel (normalized to [-1, 1])\n",
    "        ab: Color channels (normalized to [-1, 1])\n",
    "    Returns:\n",
    "        RGB image\n",
    "    \"\"\"\n",
    "    L = (L + 1.) * 50.  # Rescale L to [0, 100]\n",
    "    ab = ab * 110.      # Rescale ab to [-110, 110]\n",
    "    Lab = np.concatenate([L, ab], axis=0).transpose(1, 2, 0)  # Combine channels\n",
    "    return lab2rgb(Lab)\n",
    "\n",
    "def plot_results(original_images, grayscale_images, generated_images, num_images=10):\n",
    "    \"\"\"\n",
    "    Display original, grayscale, and generated images side by side.\n",
    "    Args:\n",
    "        original_images: List or array of original color images.\n",
    "        grayscale_images: List or array of grayscale images.\n",
    "        generated_images: List or array of generated colorized images.\n",
    "        num_images: Number of images to display.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5 * num_images))\n",
    "    for i in range(num_images):\n",
    "        original = original_images[i]\n",
    "        grayscale = grayscale_images[i]\n",
    "        generated = generated_images[i]\n",
    "\n",
    "        # Plot original image\n",
    "        plt.subplot(num_images, 3, i * 3 + 1)\n",
    "        plt.imshow(original)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot grayscale image\n",
    "        plt.subplot(num_images, 3, i * 3 + 2)\n",
    "        plt.imshow(grayscale[0], cmap=\"gray\")\n",
    "        plt.title(\"Grayscale Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot generated image\n",
    "        plt.subplot(num_images, 3, i * 3 + 3)\n",
    "        plt.imshow(generated)\n",
    "        plt.title(\"Generated Image\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assume `original_images` are in RGB, `grayscale_images` are single-channel, and `predicted_images` are the model outputs.\n",
    "# Convert predictions from LAB to RGB before displaying.\n",
    "\n",
    "# Placeholder for 10 original images, grayscale inputs, and generated predictions\n",
    "original_images = [lab_to_rgb(data['L'][i].cpu().numpy(), data['ab'][i].cpu().numpy()) for i in range(10)]\n",
    "grayscale_images = [data['L'][i].cpu().numpy() for i in range(10)]\n",
    "generated_images = [lab_to_rgb(data['L'][i].cpu().numpy(), model.fake_color[i].detach().cpu().numpy()) for i in range(10)]\n",
    "\n",
    "# Display results\n",
    "plot_results(original_images, grayscale_images, generated_images, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cf95c8fd-8a33-4659-adb4-13d28639f496",
    "_uuid": "257be63e-0f3f-4c1b-b47d-f6149a65ce51",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-09T16:00:44.592660Z",
     "iopub.status.idle": "2024-12-09T16:00:44.592979Z",
     "shell.execute_reply": "2024-12-09T16:00:44.592812Z",
     "shell.execute_reply.started": "2024-12-09T16:00:44.592798Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import copy\n",
    "\n",
    "def cross_validate(model_class, dataset, k_folds=5, epochs=10, batch_size=16, lr=1e-4, lambda_L1=100.):\n",
    "    \"\"\"\n",
    "    Perform K-fold cross-validation for the given model and dataset.\n",
    "\n",
    "    Args:\n",
    "        model_class: The model class to be instantiated for each fold.\n",
    "        dataset: The dataset to split into K folds.\n",
    "        k_folds: Number of folds for cross-validation.\n",
    "        epochs: Number of epochs to train each fold.\n",
    "        batch_size: Batch size for DataLoader.\n",
    "        lr: Learning rate for optimizer.\n",
    "        lambda_L1: Weight for L1 loss in generator.\n",
    "\n",
    "    Returns:\n",
    "        Average loss and metrics over all folds.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=123)\n",
    "    fold_results = []\n",
    "\n",
    "    # Split dataset into K folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "        # Create dataloaders for this fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_dl = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        val_dl = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Initialize model\n",
    "        model = model_class(lr_G=lr, lambda_L1=lambda_L1)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for batch_data in train_dl:\n",
    "                model.setup_input(batch_data)\n",
    "                model.optimize()\n",
    "\n",
    "            # Validate the model\n",
    "            model.eval()\n",
    "            val_loss_meter = AverageMeter()\n",
    "            with torch.no_grad():\n",
    "                for batch_data in val_dl:\n",
    "                    model.setup_input(batch_data)\n",
    "                    model.forward()\n",
    "                    val_loss = model.L1criterion(model.fake_color, model.ab)\n",
    "                    val_loss_meter.update(val_loss.item(), batch_data['L'].size(0))\n",
    "\n",
    "            print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{epochs}, Validation L1 Loss: {val_loss_meter.avg:.5f}\")\n",
    "\n",
    "        # Store results for this fold\n",
    "        fold_results.append(val_loss_meter.avg)\n",
    "\n",
    "    # Compute average loss across all folds\n",
    "    avg_loss = np.mean(fold_results)\n",
    "    print(f\"\\nCross-validation complete. Average Validation L1 Loss: {avg_loss:.5f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1e1fbf6-48af-402d-8c81-a3354e3933dd",
    "_uuid": "d49b48ff-de43-4900-81e6-ec4db5af8d6b",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-12-09T16:00:44.593813Z",
     "iopub.status.idle": "2024-12-09T16:00:44.594122Z",
     "shell.execute_reply": "2024-12-09T16:00:44.594000Z",
     "shell.execute_reply.started": "2024-12-09T16:00:44.593985Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "dataset = ColorizationDataset(paths=train_paths, split='train')\n",
    "\n",
    "# Perform cross-validation\n",
    "avg_loss = cross_validate(\n",
    "    model_class=MainModel,\n",
    "    dataset=dataset,\n",
    "    k_folds=5,         # 5-fold cross-validation\n",
    "    epochs=10,         # 10 epochs per fold\n",
    "    batch_size=16,     # Batch size\n",
    "    lr=1e-4,           # Learning rate\n",
    "    lambda_L1=100.     # L1 loss weight\n",
    ")\n",
    "\n",
    "print(f\"Final Cross-Validation Average Loss: {avg_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6e33023e-ac71-46cb-94e0-9928a59e7380",
    "_uuid": "8cfabe9f-f826-445b-84e7-1aa87b52ea4c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41cf7ede-a88a-447d-b739-72aad98bf7df",
    "_uuid": "80b5fa38-a99d-44ec-97f1-a879688e4ea6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 187606,
     "modelInstanceId": 165286,
     "sourceId": 193805,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
