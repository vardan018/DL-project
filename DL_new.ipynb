{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6799,
          "databundleVersionId": 4225553,
          "sourceType": "competition"
        },
        {
          "sourceId": 10121862,
          "sourceType": "datasetVersion",
          "datasetId": 6245757
        },
        {
          "sourceId": 193397,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 164945,
          "modelId": 187267
        },
        {
          "sourceId": 193967,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 165421,
          "modelId": 187743
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "DL-new",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "32URqNLcsDOk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "imagenet_object_localization_challenge_path = kagglehub.competition_download('imagenet-object-localization-challenge')\n",
        "dipitgolechha7_imagenetsubsub_path = kagglehub.dataset_download('dipitgolechha7/imagenetsubsub')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "9T_rOEOZsDOn"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "Path.ls = lambda x: list(x.iterdir())\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "_uuid": "5baa0f55-86a3-4e33-9e14-ce2576a82663",
        "_cell_guid": "ad019863-2545-46c5-8201-c1125792e622",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:39.810487Z",
          "iopub.execute_input": "2024-12-09T17:56:39.811222Z",
          "iopub.status.idle": "2024-12-09T17:56:39.817383Z",
          "shell.execute_reply.started": "2024-12-09T17:56:39.811191Z",
          "shell.execute_reply": "2024-12-09T17:56:39.816517Z"
        },
        "id": "8SqcAE27sDOn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet"
      ],
      "metadata": {
        "_uuid": "30fb4640-bbf9-47cc-9629-8b1c99f3dd0d",
        "_cell_guid": "c48655ef-314b-43d0-871d-b168285b07c0",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:40.24342Z",
          "iopub.execute_input": "2024-12-09T17:56:40.243736Z",
          "iopub.status.idle": "2024-12-09T17:56:40.247929Z",
          "shell.execute_reply.started": "2024-12-09T17:56:40.243711Z",
          "shell.execute_reply": "2024-12-09T17:56:40.246951Z"
        },
        "id": "0jukipTosDOo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path to the training data\n",
        "color_path = '/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train'\n",
        "\n",
        "# Get all class directories\n",
        "class_dirs = [d for d in os.listdir(color_path) if os.path.isdir(os.path.join(color_path, d))]\n",
        "\n",
        "max_images = 10000\n",
        "all_images = []\n",
        "np.random.seed(100)\n",
        "\n",
        "# Gather up to 1000 images total\n",
        "for class_dir in class_dirs:\n",
        "    if len(all_images) >= max_images:\n",
        "        break\n",
        "    class_path_pattern = os.path.join(color_path, class_dir, '*.JPEG')\n",
        "    class_images = glob.glob(class_path_pattern)\n",
        "    np.random.shuffle(class_images)  # Shuffle to get a random sample from this class\n",
        "    needed = max_images - len(all_images)\n",
        "    to_add = class_images[:needed]\n",
        "    all_images.extend(to_add)\n",
        "\n",
        "print(\"Total images collected:\", len(all_images))\n",
        "\n",
        "# Split into training and validation sets (80% train, 20% val)\n",
        "train_paths, val_paths = train_test_split(all_images, test_size=0.2, random_state=123)\n",
        "\n",
        "print(\"Total training images:\", len(train_paths))\n",
        "print(\"Total validation images:\", len(val_paths))\n",
        "\n",
        "# Display a few training images\n",
        "_, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "for ax, img_path in zip(axes.flatten(), train_paths[:16]):\n",
        "    img = Image.open(img_path)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "0e5d9db8-abbd-4b29-8035-6ddc75475335",
        "_cell_guid": "906d7e48-18a2-445e-aa33-8284e6720800",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:41.50371Z",
          "iopub.execute_input": "2024-12-09T17:56:41.504424Z",
          "iopub.status.idle": "2024-12-09T17:56:43.512665Z",
          "shell.execute_reply.started": "2024-12-09T17:56:41.50439Z",
          "shell.execute_reply": "2024-12-09T17:56:43.51113Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Fe_LsBBrsDOo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 256\n",
        "\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE), Image.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "            ])\n",
        "        else:\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE), Image.BICUBIC)\n",
        "\n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\")\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1.\n",
        "        ab = img_lab[[1, 2], ...] / 110.\n",
        "        return {'L': L, 'ab': ab}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "def make_dataloaders(paths, split='train', batch_size=16, n_workers=4, pin_memory=True):\n",
        "    dataset = ColorizationDataset(paths, split=split)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                            num_workers=n_workers, pin_memory=pin_memory, shuffle=(split=='train'))\n",
        "    return dataloader\n",
        "\n",
        "train_dl = make_dataloaders(train_paths, split='train', batch_size=16)\n",
        "val_dl = make_dataloaders(val_paths, split='val', batch_size=16)\n",
        "\n",
        "data = next(iter(train_dl))\n",
        "Ls, abs_ = data['L'], data['ab']\n",
        "print(\"Train batch shapes:\", Ls.shape, abs_.shape)\n",
        "print(\"Number of batches:\", len(train_dl), \"train,\", len(val_dl), \"val\")"
      ],
      "metadata": {
        "_uuid": "66d99cbf-517f-48d4-9315-d67a79419ff0",
        "_cell_guid": "153aecb7-5daf-4609-9327-4f30c23422ca",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:43.514605Z",
          "iopub.execute_input": "2024-12-09T17:56:43.514897Z",
          "iopub.status.idle": "2024-12-09T17:56:44.506646Z",
          "shell.execute_reply.started": "2024-12-09T17:56:43.51487Z",
          "shell.execute_reply": "2024-12-09T17:56:44.505541Z"
        },
        "id": "qUQzvbldsDOo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "        if input_c is None: input_c = nf\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=False)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(ni)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = nn.BatchNorm2d(nf)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            if dropout: up += [nn.Dropout(0.5)]\n",
        "            model = down + [submodule] + up\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "        for _ in range(n_down - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
        "        out_filters = num_filters * 8\n",
        "        for _ in range(3):\n",
        "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
        "            out_filters //= 2\n",
        "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
        "                  for i in range(n_down)]\n",
        "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
        "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n",
        "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
        "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "_uuid": "0d061446-1cf2-485e-b0b2-ae290c437d39",
        "_cell_guid": "dd9d16ee-c4c8-4002-beff-09058f6007ac",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.509332Z",
          "iopub.execute_input": "2024-12-09T17:56:44.509777Z",
          "iopub.status.idle": "2024-12-09T17:56:44.526001Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.509729Z",
          "shell.execute_reply": "2024-12-09T17:56:44.525114Z"
        },
        "id": "Nf77VT2qsDOp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def forward(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss\n",
        "\n",
        "def init_weights(net, init='norm', gain=0.02):\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "            if init == 'norm':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif 'BatchNorm2d' in classname:\n",
        "            nn.init.normal_(m.weight.data, 1., gain)\n",
        "            nn.init.constant_(m.bias.data, 0.)\n",
        "\n",
        "    net.apply(init_func)\n",
        "    print(f\"model initialized with {init} initialization\")\n",
        "    return net\n",
        "\n",
        "def init_model(model, device):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model\n",
        "\n",
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def create_loss_meters():\n",
        "    loss_D_fake = AverageMeter()\n",
        "    loss_D_real = AverageMeter()\n",
        "    loss_D = AverageMeter()\n",
        "    loss_G_GAN = AverageMeter()\n",
        "    loss_G_L1 = AverageMeter()\n",
        "    loss_G = AverageMeter()\n",
        "\n",
        "    return {'loss_D_fake': loss_D_fake,\n",
        "            'loss_D_real': loss_D_real,\n",
        "            'loss_D': loss_D,\n",
        "            'loss_G_GAN': loss_G_GAN,\n",
        "            'loss_G_L1': loss_G_L1,\n",
        "            'loss_G': loss_G}\n",
        "\n",
        "def update_losses(model, loss_meter_dict, count):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        loss = getattr(model, loss_name)\n",
        "        loss_meter.update(loss.item(), count=count)"
      ],
      "metadata": {
        "_uuid": "9db342d3-cd2b-4c5c-a30f-6a00ffa68650",
        "_cell_guid": "ed10b0d3-752b-4ebe-b46e-f0eeb418d578",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.527336Z",
          "iopub.execute_input": "2024-12-09T17:56:44.527632Z",
          "iopub.status.idle": "2024-12-09T17:56:44.542279Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.527593Z",
          "shell.execute_reply": "2024-12-09T17:56:44.541201Z"
        },
        "id": "uVjdhOk3sDOp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(model, data, save=True):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    model.net_G.train()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 12))  # Adjusted height for row titles\n",
        "    rows, cols = 3, 5  # 3 rows (Grayscale, Model generated, Actual), up to 5 columns\n",
        "\n",
        "    # Add row titles\n",
        "    plt.subplot(rows, cols, 1).set_title(\"Grayscale Image\", fontsize=16, loc='left')\n",
        "    plt.subplot(rows, cols, cols + 1).set_title(\"Model Generated Image\", fontsize=16, loc='left')\n",
        "    plt.subplot(rows, cols, 2 * cols + 1).set_title(\"Actual Image\", fontsize=16, loc='left')\n",
        "\n",
        "    for i in range(min(5, L.size(0))):\n",
        "        # Grayscale Image (Row 1)\n",
        "        ax = plt.subplot(rows, cols, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        # Model Generated Image (Row 2)\n",
        "        ax = plt.subplot(rows, cols, i + 1 + cols)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        # Actual Image (Row 3)\n",
        "        ax = plt.subplot(rows, cols, i + 1 + 2 * cols)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"images_new/colorization_{time.time()}.png\")\n",
        "\n",
        "def log_results(loss_meter_dict, log_file, epoch, iteration):\n",
        "    \"\"\"\n",
        "    Log the training results to a CSV file and print them to the console.\n",
        "    \"\"\"\n",
        "    with open(log_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for loss_name, loss_meter in loss_meter_dict.items():\n",
        "            print(f\"{loss_name}: {loss_meter.avg:.5f}\")  # Print to console\n",
        "            # Append the results to the CSV file\n",
        "            writer.writerow([epoch, iteration, loss_name, loss_meter.avg])"
      ],
      "metadata": {
        "_uuid": "52ae7c46-d591-4e28-a980-37e1144e6fb0",
        "_cell_guid": "d5d6406c-22a0-4913-a6b5-8575154d6f84",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.543942Z",
          "iopub.execute_input": "2024-12-09T17:56:44.54421Z",
          "iopub.status.idle": "2024-12-09T17:56:44.558289Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.544185Z",
          "shell.execute_reply": "2024-12-09T17:56:44.55745Z"
        },
        "id": "5vr_QfFDsDOq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
        "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = lambda_L1\n",
        "\n",
        "        if net_G is None:\n",
        "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
        "        else:\n",
        "            self.net_G = net_G.to(self.device)\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    def set_requires_grad(self, model, requires_grad=True):\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "\n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)\n",
        "        self.ab = data['ab'].to(self.device)\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "\n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "        real_preds = self.net_D(real_image)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self):\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.set_requires_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        self.net_G.train()\n",
        "        self.set_requires_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()"
      ],
      "metadata": {
        "_uuid": "7b397922-d1b8-4ff3-a48a-a5ce737e5daf",
        "_cell_guid": "973ec7d5-9c10-4615-a414-a7c672d84995",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.559209Z",
          "iopub.execute_input": "2024-12-09T17:56:44.559516Z",
          "iopub.status.idle": "2024-12-09T17:56:44.575822Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.55949Z",
          "shell.execute_reply": "2024-12-09T17:56:44.575099Z"
        },
        "id": "tlo70sIksDOq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Ensure DataLoader tensors are on the correct device\n",
        "def move_batch_to_device(batch, device):\n",
        "    return {key: value.to(device) for key, value in batch.items()}\n",
        "\n",
        "import random\n",
        "def train_model(model, train_dl, epochs, display_every=200, log_file=\"logs_training_final.csv\"):\n",
        "    # Prepare the CSV file for logging\n",
        "    with open(log_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Write the header\n",
        "        writer.writerow([\"Epoch\", \"Iteration\", \"Loss Name\", \"Average Loss\"])\n",
        "\n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters()\n",
        "        i = 0\n",
        "        # Generate a random interval for image visualization for this epoch\n",
        "        visualize_every = random.randint(1, 499)\n",
        "        for batch_data in tqdm(train_dl):\n",
        "            model.setup_input(batch_data)\n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=batch_data['L'].size(0))\n",
        "            i += 1\n",
        "\n",
        "            # Log results at fixed intervals\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict, log_file, epoch=e + 1, iteration=i)\n",
        "\n",
        "            # Visualize images at random intervals\n",
        "            if i % visualize_every == 0:\n",
        "                print(f\"Visualizing at random iteration {i} (interval: {visualize_every})\")\n",
        "                # Fetch a new batch of validation data for visualization\n",
        "                data = next(iter(val_dl))\n",
        "                visualize(model, data, save=True)"
      ],
      "metadata": {
        "_uuid": "85a826d8-12b9-449c-8c8e-5be517fbf3c1",
        "_cell_guid": "12637647-1d6e-4458-bc6b-4f03efed4288",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.57675Z",
          "iopub.execute_input": "2024-12-09T17:56:44.577027Z",
          "iopub.status.idle": "2024-12-09T17:56:44.595067Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.577002Z",
          "shell.execute_reply": "2024-12-09T17:56:44.594351Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ky2crvbGsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_res_unet(n_input=1, n_output=2, size=256):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # First, instantiate the resnet18 model with pretrained weights\n",
        "    backbone = resnet18(pretrained=True)\n",
        "    # Now pass this instantiated model to create_body\n",
        "    body = create_body(backbone, n_in=n_input, cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G\n",
        "\n",
        "\n",
        "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
        "    for e in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for batch_data in tqdm(train_dl):\n",
        "            L, ab = batch_data['L'].to(device), batch_data['ab'].to(device)\n",
        "            preds = net_G(L)\n",
        "            loss = criterion(preds, ab)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "\n",
        "        print(f\"Epoch {e + 1}/{epochs}\")\n",
        "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")"
      ],
      "metadata": {
        "_uuid": "b62db569-4d91-4eab-9805-22a19d1e342f",
        "_cell_guid": "f9dfcbb1-1566-4bdf-bda8-e407a0b90254",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:44.595974Z",
          "iopub.execute_input": "2024-12-09T17:56:44.596247Z",
          "iopub.status.idle": "2024-12-09T17:56:44.607408Z",
          "shell.execute_reply.started": "2024-12-09T17:56:44.596223Z",
          "shell.execute_reply": "2024-12-09T17:56:44.606712Z"
        },
        "id": "f7BCXo3IsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrain the generator\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "opt_g = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "criterion_L1 = nn.L1Loss()\n",
        "\n",
        "print(\"Pretraining the generator with L1 loss...\")\n",
        "pretrain_generator(net_G, train_dl, opt_g, criterion_L1, epochs=20)\n",
        "\n",
        "# Save the pretrained generator weights\n",
        "torch.save(net_G.state_dict(), \"res18-unet-v2.pt\")\n",
        "print(\"Pretraining complete and weights saved.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "_uuid": "95a3799a-0763-4ebb-8f26-2b15ec646917",
        "_cell_guid": "0a087a84-de36-4178-9546-8d07b50a4987",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "miVt8nQdsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\""
      ],
      "metadata": {
        "_uuid": "4e48bfe8-f686-461d-80c0-dd56e28b11a7",
        "_cell_guid": "413064c7-26b0-431d-81d6-029111460e73",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T18:37:20.684974Z",
          "iopub.status.idle": "2024-12-08T18:37:20.68532Z",
          "shell.execute_reply.started": "2024-12-08T18:37:20.685153Z",
          "shell.execute_reply": "2024-12-08T18:37:20.68517Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "c4R4HqA8sDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the pretrained weights\n",
        "pretrained_weights_path = \"/kaggle/working/res18-unet.pt\"  # Update this path if the weights are saved elsewhere\n",
        "\n",
        "# Load the pretrained generator\n",
        "print(\"Loading pretrained generator weights...\")\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Build the generator architecture\n",
        "net_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))  # Load weights\n",
        "net_G = net_G.to(device)  # Move the model to the appropriate device (GPU/CPU)\n",
        "net_G.eval()  # Set the model to evaluation mode (optional, for inference)\n",
        "\n",
        "print(\"Pretrained generator loaded successfully!\")\n",
        "\"\"\""
      ],
      "metadata": {
        "_uuid": "e8d05388-04d3-46e3-b9e2-ce6613bfe372",
        "_cell_guid": "d03b43d3-0fcd-4c95-bff3-19c1ec766b15",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "DUIFYdzMsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "# Ensure the images directory exists\n",
        "#os.makedirs(\"/kaggle/working/images\", exist_ok=True)\n",
        "#!rm /kaggle/working/images/colorization_1733694174.787311.png\n",
        "#!mkdir images_new"
      ],
      "metadata": {
        "_uuid": "6b640ac0-bc81-40d5-8cd8-0e1e7a346977",
        "_cell_guid": "53706950-3e7f-475c-9975-9be30970d320",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T17:56:46.799722Z",
          "iopub.execute_input": "2024-12-09T17:56:46.800416Z",
          "iopub.status.idle": "2024-12-09T17:56:46.804272Z",
          "shell.execute_reply.started": "2024-12-09T17:56:46.800384Z",
          "shell.execute_reply": "2024-12-09T17:56:46.803239Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "V8HgUHflsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained generator from the working directory\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "\n",
        "# Ensure the model is on the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net_G = net_G.to(device)\n",
        "\n",
        "# Load the pretrained weights into the generator\n",
        "pretrained_weights_path = \"/kaggle/input/res18-v2/other/default/1/res18-unet-v2.pt\"  # Path to the weights file\n",
        "net_G.load_state_dict(torch.load(pretrained_weights_path, map_location=device))\n",
        "print(\"Pretrained weights loaded into the generator.\")\n",
        "\n",
        "# Create the main model with the pretrained net_G\n",
        "model = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\n",
        "model = model.to(device)  # Ensure the full model is on the GPU\n",
        "print(\"Main model created and moved to the GPU (if available).\")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the full model (GAN + L1) now...\")\n",
        "train_model(model, train_dl, epochs=50, display_every=200)\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "_uuid": "c2c2baba-2807-41f3-b6eb-4942346293cf",
        "_cell_guid": "2cc47168-dee7-4210-bf75-6be08ff27c1b",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "g3lixDVCsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained generator\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
        "\n",
        "# Create the main model with the pretrained net_G\n",
        "model = MainModel(net_G=net_G, lr_G=2e-4, lr_D=2e-4, beta1=0.5, beta2=0.999, lambda_L1=100.)\n",
        "print(\"Training the full model (GAN + L1) now...\")\n",
        "train_model(model, train_dl, epochs=50, display_every=200)\n",
        "print(\"Training complete.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "_uuid": "415280de-4cec-43cd-b7ba-4c3aeea621f5",
        "_cell_guid": "2c3d3878-6242-417f-a4bb-7aff6e2ae5d3",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "AZY6duhqsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generator weights\n",
        "generator_save_path = \"/kaggle/working/net_G_final.pt\"\n",
        "torch.save(model.net_G.state_dict(), generator_save_path)\n",
        "print(f\"Generator weights saved to {generator_save_path}\")\n",
        "\n",
        "# Save the entire model\n",
        "main_model_save_path = \"/kaggle/working/main_model_final.pt\"\n",
        "torch.save({\n",
        "    'net_G': model.net_G.state_dict(),\n",
        "    'net_D': model.net_D.state_dict(),\n",
        "    'opt_G': model.opt_G.state_dict(),\n",
        "    'opt_D': model.opt_D.state_dict()\n",
        "}, main_model_save_path)\n",
        "print(f\"Full model saved to {main_model_save_path}\")"
      ],
      "metadata": {
        "_uuid": "38322f12-59ad-4501-ad57-36dbe4645be6",
        "_cell_guid": "51f2ee53-ccc9-4b2f-9cd1-812ab9fe0b01",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0sqBUd2osDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "n3ZgQa8nsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "a6VB_w1lsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.color import lab2rgb\n",
        "import os\n",
        "\n",
        "# Ensure the directory for saving plots exists\n",
        "os.makedirs(\"predicted_samples\", exist_ok=True)\n",
        "\n",
        "# Load the generator model\n",
        "def load_model(generator_path, device):\n",
        "    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n",
        "    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n",
        "    net_G.eval()  # Set to evaluation mode\n",
        "    return net_G.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\n",
        "generator = load_model(generator_path, device)\n",
        "\n",
        "# Function to convert LAB to RGB\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
        "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
        "    return np.stack(rgb_imgs)\n",
        "\n",
        "# Metrics Calculation\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(color, predicted):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics: MSE, PSNR, and SSIM with robust handling for small images and explicit channel_axis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Mean Squared Error\n",
        "        mse = np.mean((color - predicted) ** 2)\n",
        "\n",
        "        # Peak Signal-to-Noise Ratio\n",
        "        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
        "\n",
        "        # Determine minimum dimension of the image\n",
        "        min_dim = min(color.shape[0], color.shape[1])\n",
        "\n",
        "        # Dynamically set `win_size` or skip SSIM if the image is too small\n",
        "        if min_dim < 7:\n",
        "            print(f\"Skipping SSIM for image with insufficient dimensions: {color.shape}\")\n",
        "            ssim_value = 0.0\n",
        "        else:\n",
        "            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n",
        "            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n",
        "\n",
        "        return mse, psnr, ssim_value\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        return float('inf'), float('inf'), 0.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualization\n",
        "def plot_images_with_metrics(color, grayscale, predicted, mse, psnr, ssim_value, sample_idx):\n",
        "    try:\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Color Image', color='green', fontsize=20)\n",
        "        plt.imshow(color)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Grayscale Image', color='black', fontsize=20)\n",
        "        plt.imshow(grayscale, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f'Predicted Image\\nMSE: {mse:.4f}\\nPSNR: {psnr:.2f} dB\\nSSIM: {ssim_value:.4f}',\n",
        "                  color='red', fontsize=16)\n",
        "        plt.imshow(predicted)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.savefig(f'predicted_samples/predicted_sample_{sample_idx}.png', bbox_inches='tight')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting images: {e}\")\n",
        "\n",
        "# Evaluation loop\n",
        "results = []\n",
        "for i, data in enumerate(val_dl):  # Iterate over validation DataLoader\n",
        "    if i >= 10:  # Test on first 10 batches (adjust as needed)\n",
        "        break\n",
        "\n",
        "    L = data['L'].to(device)\n",
        "    ab_real = data['ab'].to(device)\n",
        "\n",
        "    # Predict color channels\n",
        "    with torch.no_grad():\n",
        "        ab_predicted = generator(L).cpu().numpy()\n",
        "\n",
        "    # Convert to RGB for visualization and metrics\n",
        "    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n",
        "    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
        "\n",
        "    for idx in range(len(L)):\n",
        "        real_img = real_rgb[idx]\n",
        "        predicted_img = predicted_rgb[idx]\n",
        "\n",
        "        print(f\"Processing Image {idx}: Real shape: {real_img.shape}, Predicted shape: {predicted_img.shape}\")\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n",
        "        print(f\"Metrics for Image {idx}: MSE={mse:.4f}, PSNR={psnr:.2f} dB, SSIM={ssim_value:.4f}\")\n",
        "\n",
        "    for idx in range(len(L)):\n",
        "        # Calculate metrics\n",
        "        mse, psnr, ssim_value = calculate_metrics(real_rgb[idx], predicted_rgb[idx])\n",
        "        results.append([mse, psnr, ssim_value])\n",
        "\n",
        "        # Plot and save images with metrics\n",
        "        plot_images_with_metrics(\n",
        "            real_rgb[idx],\n",
        "            L[idx][0].cpu().numpy(),  # Grayscale image\n",
        "            predicted_rgb[idx],\n",
        "            mse,\n",
        "            psnr,\n",
        "            ssim_value,\n",
        "            sample_idx=i * len(L) + idx\n",
        "        )\n",
        "\n",
        "# Calculate average metrics\n",
        "if results:\n",
        "    average_metrics = np.mean(results, axis=0)\n",
        "    print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\n",
        "else:\n",
        "    print(\"No results to average.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T18:20:36.826365Z",
          "iopub.execute_input": "2024-12-09T18:20:36.826725Z",
          "iopub.status.idle": "2024-12-09T18:23:03.399599Z",
          "shell.execute_reply.started": "2024-12-09T18:20:36.826695Z",
          "shell.execute_reply": "2024-12-09T18:23:03.398603Z"
        },
        "id": "PojBWzkbsDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "# Sort results by MSE (ascending), PSNR (descending), and SSIM (descending)\n",
        "sorted_results = sorted(\n",
        "    enumerate(results),  # Include the index to identify which image\n",
        "    key=lambda x: (x[1][0], -x[1][1], -x[1][2])  # Sort by MSE (low), then PSNR (high), then SSIM (high)\n",
        ")\n",
        "\n",
        "# Extract the top 100 results\n",
        "top_100_results = sorted_results[:100]\n",
        "\n",
        "# Create a PDF file to save the plots\n",
        "output_pdf_path = \"/kaggle/working/top_100_predictions.pdf\"\n",
        "pdf = PdfPages(output_pdf_path)\n",
        "\n",
        "# Function to add images to the PDF\n",
        "def add_prediction_to_pdf(pdf, real_img, grayscale_img, predicted_img, mse, psnr, ssim_value, rank):\n",
        "    \"\"\"\n",
        "    Add the ground truth, grayscale input, and predicted image with metrics to a PDF.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Ground Truth Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(real_img)\n",
        "    plt.title(\"Ground Truth\", fontsize=14)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Grayscale Input Image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(grayscale_img, cmap=\"gray\")\n",
        "    plt.title(\"Grayscale Input\", fontsize=14)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Predicted Image\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(predicted_img)\n",
        "    plt.title(f\"Prediction\\nMSE: {mse:.4f}, PSNR: {psnr:.2f}, SSIM: {ssim_value:.4f}\", fontsize=12)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(f\"Rank: {rank}\", fontsize=16, color=\"blue\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the current figure to the PDF\n",
        "    pdf.savefig()\n",
        "    plt.close()\n",
        "\n",
        "# Add the top 100 predictions to the PDF\n",
        "for rank, (index, metrics) in enumerate(top_100_results, start=1):\n",
        "    mse, psnr, ssim_value, *extra_metrics = metrics  # Unpack the first three metrics\n",
        "\n",
        "    # Retrieve the real image, grayscale input, and predicted image\n",
        "    L = val_dl.dataset[index][\"L\"].numpy()  # Grayscale input (normalized)\n",
        "    ab_real = val_dl.dataset[index][\"ab\"].numpy()  # Ground truth color\n",
        "    ab_predicted = generator(torch.tensor(L).unsqueeze(0).to(device)).cpu().detach().numpy().squeeze()\n",
        "\n",
        "    # Convert LAB to RGB\n",
        "    real_img = lab_to_rgb(L[np.newaxis, ...], ab_real[np.newaxis, ...])[0]\n",
        "    predicted_img = lab_to_rgb(L[np.newaxis, ...], ab_predicted[np.newaxis, ...])[0]\n",
        "    grayscale_img = L[0]  # Grayscale image for visualization\n",
        "\n",
        "    # Add the prediction to the PDF\n",
        "    add_prediction_to_pdf(pdf, real_img, grayscale_img, predicted_img, mse, psnr, ssim_value, rank)\n",
        "\n",
        "# Close the PDF file\n",
        "pdf.close()\n",
        "\n",
        "print(f\"PDF saved to: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T19:11:45.249693Z",
          "iopub.execute_input": "2024-12-09T19:11:45.25035Z",
          "iopub.status.idle": "2024-12-09T19:12:38.322361Z",
          "shell.execute_reply.started": "2024-12-09T19:11:45.250307Z",
          "shell.execute_reply": "2024-12-09T19:12:38.321389Z"
        },
        "id": "MgeZELx8sDOr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.color import lab2rgb\n",
        "import warnings\n",
        "from scipy.linalg import sqrtm\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the generator model\n",
        "def load_model(generator_path, device):\n",
        "    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n",
        "    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n",
        "    net_G.eval()  # Set to evaluation mode\n",
        "    return net_G.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\n",
        "generator = load_model(generator_path, device)\n",
        "\n",
        "# Convert LAB to RGB\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
        "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
        "    return np.stack(rgb_imgs)\n",
        "\n",
        "# FID Helper Functions\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "def calculate_fid(real_features, fake_features):\n",
        "    \"\"\"\n",
        "    Calculate FID between real and fake features.\n",
        "    \"\"\"\n",
        "    # Compute mean and covariance for real and generated features\n",
        "    mu1 = np.mean(real_features, axis=0)\n",
        "    sigma1 = np.cov(real_features, rowvar=False)\n",
        "    mu2 = np.mean(fake_features, axis=0)\n",
        "    sigma2 = np.cov(fake_features, rowvar=False)\n",
        "\n",
        "    # Compute the mean difference\n",
        "    diff = mu1 - mu2\n",
        "    diff_squared = diff @ diff\n",
        "\n",
        "    # Compute the square root of the product of covariance matrices\n",
        "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
        "\n",
        "    # Handle imaginary numbers from sqrtm (they can occur due to numerical instability)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    # Calculate FID\n",
        "    fid = diff_squared + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "def extract_features(images, model, batch_size=32):\n",
        "    \"\"\"\n",
        "    Extract features using a pre-trained ResNet50 model.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    transform = Resize((224, 224))  # ResNet50 expects (224, 224) inputs\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)  # (B, H, W, C) -> (B, C, H, W)\n",
        "        batch = transform(batch)  # Resize to (224, 224)\n",
        "        if batch.ndim != 4:\n",
        "            print(f\"Invalid batch shape: {batch.shape}. Skipping this batch.\")\n",
        "            continue\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch)\n",
        "        features.append(pred.cpu().numpy())\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "# Metrics Calculation\n",
        "def calculate_metrics(color, predicted):\n",
        "    \"\"\"\n",
        "    Calculate MSE, PSNR, and SSIM.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mse = np.mean((color - predicted) ** 2)\n",
        "        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
        "\n",
        "        min_dim = min(color.shape[0], color.shape[1])\n",
        "        if min_dim < 7:\n",
        "            ssim_value = 0.0\n",
        "        else:\n",
        "            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n",
        "            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n",
        "\n",
        "        return mse, psnr, ssim_value\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        return float('inf'), float('inf'), 0.0\n",
        "\n",
        "# Load ResNet50 for FID\n",
        "resnet_model = resnet50(pretrained=True).to(device)\n",
        "resnet_model.eval()\n",
        "\n",
        "# Evaluation Loop\n",
        "results = []  # Store MSE, PSNR, SSIM, FID for all images\n",
        "all_mse, all_psnr, all_ssim = [], [], []\n",
        "real_features, fake_features = [], []\n",
        "\n",
        "for i, data in enumerate(val_dl):\n",
        "    L = data['L'].to(device)\n",
        "    ab_real = data['ab'].to(device)\n",
        "\n",
        "    # Predict color channels\n",
        "    with torch.no_grad():\n",
        "        ab_predicted = generator(L).cpu().numpy()\n",
        "\n",
        "    # Convert to RGB\n",
        "    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n",
        "    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
        "\n",
        "    # Collect real and fake features for FID\n",
        "    real_features.append(real_rgb)\n",
        "    fake_features.append(predicted_rgb)\n",
        "\n",
        "    for idx in range(len(L)):\n",
        "        real_img = real_rgb[idx]\n",
        "        predicted_img = predicted_rgb[idx]\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n",
        "        results.append([mse, psnr, ssim_value])\n",
        "        all_mse.append(mse)\n",
        "        all_psnr.append(psnr)\n",
        "        all_ssim.append(ssim_value)\n",
        "\n",
        "# FID Calculation\n",
        "real_features_np = np.concatenate(real_features)\n",
        "fake_features_np = np.concatenate(fake_features)\n",
        "\n",
        "real_features = extract_features(real_features_np, resnet_model)\n",
        "fake_features = extract_features(fake_features_np, resnet_model)\n",
        "\n",
        "fid_value = calculate_fid(real_features, fake_features)\n",
        "all_fid = [fid_value] * len(results)\n",
        "\n",
        "# Add FID to results\n",
        "results = [result + [fid_value] for result in results]\n",
        "\n",
        "# Calculate average metrics\n",
        "average_metrics = np.mean(results, axis=0)\n",
        "print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}, FID={average_metrics[3]:.4f}\")\n",
        "\n",
        "# Plotting Metrics\n",
        "def plot_metric(metric_values, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(metric_values, label=metric_name)\n",
        "    plt.xlabel(\"Image Index\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f\"{metric_name} Across Validation Images\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Separate plots for each metric\n",
        "plot_metric(all_mse, \"MSE\")\n",
        "plot_metric(all_psnr, \"PSNR (dB)\")\n",
        "plot_metric(all_ssim, \"SSIM\")\n",
        "plot_metric([fid_value] * len(all_mse), \"FID\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T19:00:31.277681Z",
          "iopub.execute_input": "2024-12-09T19:00:31.278424Z",
          "iopub.status.idle": "2024-12-09T19:01:50.246789Z",
          "shell.execute_reply.started": "2024-12-09T19:00:31.278391Z",
          "shell.execute_reply": "2024-12-09T19:01:50.245728Z"
        },
        "id": "kLMgjsfzsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average metrics (excluding FID from per-image results)\n",
        "average_metrics = np.mean(results, axis=0)\n",
        "print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\n",
        "\n",
        "# Print the global FID value\n",
        "print(f\"Global FID: {fid_value:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T19:01:50.249034Z",
          "iopub.execute_input": "2024-12-09T19:01:50.249918Z",
          "iopub.status.idle": "2024-12-09T19:01:50.256898Z",
          "shell.execute_reply.started": "2024-12-09T19:01:50.249882Z",
          "shell.execute_reply": "2024-12-09T19:01:50.255987Z"
        },
        "id": "T-uaHkPNsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming results is a list of lists: [[mse1, psnr1, ssim1], [mse2, psnr2, ssim2], ...]\n",
        "if results:\n",
        "    # Convert the results list to a NumPy array for easier manipulation\n",
        "    results_array = np.array(results)\n",
        "\n",
        "    # Calculate the average along the columns (axis=0)\n",
        "    average_metrics = np.mean(results_array, axis=0)\n",
        "\n",
        "    # Print the average metrics\n",
        "    print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\n",
        "else:\n",
        "    print(\"Results list is empty. No metrics to average.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T18:27:10.154438Z",
          "iopub.execute_input": "2024-12-09T18:27:10.15479Z",
          "iopub.status.idle": "2024-12-09T18:27:10.16077Z",
          "shell.execute_reply.started": "2024-12-09T18:27:10.15476Z",
          "shell.execute_reply": "2024-12-09T18:27:10.159929Z"
        },
        "id": "brjfn2EGsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the paths to the saved model files\n",
        "main_model_path = \"/kaggle/input/yashvidl/other/default/1/main_model_final.pt\"\n",
        "generator_weights_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\n",
        "\n",
        "# Ensure the device is set (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the generator architecture\n",
        "def build_res_unet(n_input=1, n_output=2, size=256):\n",
        "    from fastai.vision.learner import create_body\n",
        "    from torchvision.models.resnet import resnet18\n",
        "    from fastai.vision.models.unet import DynamicUnet\n",
        "    backbone = resnet18(pretrained=False)  # Pretrained=False because we're loading custom weights\n",
        "    body = create_body(backbone, n_in=n_input, cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G\n",
        "\n",
        "# Initialize the generator and discriminator\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "net_D = PatchDiscriminator(input_c=3, n_down=3, num_filters=64).to(device)\n",
        "\n",
        "# Load the saved generator weights\n",
        "print(\"Loading generator weights...\")\n",
        "net_G.load_state_dict(torch.load(generator_weights_path, map_location=device))\n",
        "print(\"Generator weights loaded successfully.\")\n",
        "\n",
        "# Load the full model state\n",
        "print(\"Loading full model state...\")\n",
        "checkpoint = torch.load(main_model_path, map_location=device)\n",
        "net_G.load_state_dict(checkpoint['net_G'])\n",
        "net_D.load_state_dict(checkpoint['net_D'])\n",
        "\n",
        "# Load optimizer states if needed\n",
        "opt_G = torch.optim.Adam(net_G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "opt_D = torch.optim.Adam(net_D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "opt_G.load_state_dict(checkpoint['opt_G'])\n",
        "opt_D.load_state_dict(checkpoint['opt_D'])\n",
        "\n",
        "print(\"Full model and optimizers loaded successfully.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T17:57:16.621583Z",
          "iopub.execute_input": "2024-12-09T17:57:16.622462Z",
          "iopub.status.idle": "2024-12-09T17:57:18.160939Z",
          "shell.execute_reply.started": "2024-12-09T17:57:16.622428Z",
          "shell.execute_reply": "2024-12-09T17:57:18.159942Z"
        },
        "id": "5G6E4maUsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorizationDatasetEval(Dataset):\n",
        "    def __init__(self, paths, size=256):\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize((size, size), Image.BICUBIC),\n",
        "        ])\n",
        "        self.size = size\n",
        "        self.paths = [path for path in paths if os.path.isfile(path)]  # Filter valid paths\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "            img = self.transforms(img)\n",
        "            img = np.array(img)\n",
        "            img_lab = rgb2lab(img).astype(\"float32\")\n",
        "            img_lab = transforms.ToTensor()(img_lab)\n",
        "            L = img_lab[[0], ...] / 50. - 1.\n",
        "            ab = img_lab[[1, 2], ...] / 110.\n",
        "            return {'L': L, 'ab': ab, 'path': self.paths[idx]}\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {self.paths[idx]}: {e}\")\n",
        "            return None  # Return None if an image fails to load\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T18:01:33.264941Z",
          "iopub.execute_input": "2024-12-09T18:01:33.265403Z",
          "iopub.status.idle": "2024-12-09T18:01:33.272482Z",
          "shell.execute_reply.started": "2024-12-09T18:01:33.265365Z",
          "shell.execute_reply": "2024-12-09T18:01:33.271565Z"
        },
        "id": "_EXPObeZsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.color import lab2rgb\n",
        "import warnings\n",
        "from scipy.linalg import sqrtm\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the generator model\n",
        "def load_model(generator_path, device):\n",
        "    net_G = build_res_unet(n_input=1, n_output=2, size=256)  # Ensure consistent architecture\n",
        "    net_G.load_state_dict(torch.load(generator_path, map_location=device))\n",
        "    net_G.eval()  # Set to evaluation mode\n",
        "    return net_G.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator_path = \"/kaggle/input/yashvidl/other/default/1/net_G_final.pt\"\n",
        "generator = load_model(generator_path, device)\n",
        "\n",
        "# Convert LAB to RGB\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = np.concatenate([L, ab], axis=1).transpose(0, 2, 3, 1)\n",
        "    rgb_imgs = [lab2rgb(img) for img in Lab]\n",
        "    return np.stack(rgb_imgs)\n",
        "\n",
        "# FID Helper Functions\n",
        "def calculate_fid(real_features, fake_features):\n",
        "    \"\"\"\n",
        "    Calculate FID between real and fake features.\n",
        "    \"\"\"\n",
        "    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
        "    mu2, sigma2 = np.mean(fake_features, axis=0), np.cov(fake_features, rowvar=False)\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
        "\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "def extract_features(images, model, batch_size=32):\n",
        "    \"\"\"\n",
        "    Extract features using a pre-trained ResNet50 model.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    transform = Resize((224, 224))  # ResNet50 expects (224, 224) inputs\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = torch.tensor(images[i:i + batch_size]).permute(0, 3, 1, 2).to(device)  # (B, H, W, C) -> (B, C, H, W)\n",
        "        batch = transform(batch)  # Resize to (224, 224)\n",
        "        if batch.ndim != 4:\n",
        "            print(f\"Invalid batch shape: {batch.shape}. Skipping this batch.\")\n",
        "            continue\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch)\n",
        "        features.append(pred.cpu().numpy())\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "# Metrics Calculation\n",
        "def calculate_metrics(color, predicted):\n",
        "    \"\"\"\n",
        "    Calculate MSE, PSNR, and SSIM.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mse = np.mean((color - predicted) ** 2)\n",
        "        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
        "\n",
        "        min_dim = min(color.shape[0], color.shape[1])\n",
        "        if min_dim < 7:\n",
        "            ssim_value = 0.0\n",
        "        else:\n",
        "            win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n",
        "            ssim_value = ssim(color, predicted, data_range=1.0, win_size=win_size, channel_axis=-1)\n",
        "\n",
        "        return mse, psnr, ssim_value\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        return float('inf'), float('inf'), 0.0\n",
        "\n",
        "# Load ResNet50 for FID\n",
        "resnet_model = resnet50(pretrained=True).to(device)\n",
        "resnet_model.eval()\n",
        "\n",
        "# Evaluation Loop\n",
        "results = []  # Store MSE, PSNR, SSIM, FID for all images\n",
        "all_mse, all_psnr, all_ssim = [], [], []\n",
        "real_features, fake_features = [], []\n",
        "\n",
        "for i, data in enumerate(val_dl):\n",
        "    L = data['L'].to(device)\n",
        "    ab_real = data['ab'].to(device)\n",
        "\n",
        "    # Predict color channels\n",
        "    with torch.no_grad():\n",
        "        ab_predicted = generator(L).cpu().numpy()\n",
        "\n",
        "    # Convert to RGB\n",
        "    predicted_rgb = lab_to_rgb(L.cpu().numpy(), ab_predicted)\n",
        "    real_rgb = lab_to_rgb(L.cpu().numpy(), ab_real.cpu().numpy())\n",
        "\n",
        "    # Collect real and fake features for FID\n",
        "    real_features.append(real_rgb)\n",
        "    fake_features.append(predicted_rgb)\n",
        "\n",
        "    for idx in range(len(L)):\n",
        "        real_img = real_rgb[idx]\n",
        "        predicted_img = predicted_rgb[idx]\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse, psnr, ssim_value = calculate_metrics(real_img, predicted_img)\n",
        "        results.append([mse, psnr, ssim_value])\n",
        "        all_mse.append(mse)\n",
        "        all_psnr.append(psnr)\n",
        "        all_ssim.append(ssim_value)\n",
        "\n",
        "# FID Calculation\n",
        "real_features_np = np.concatenate(real_features)\n",
        "fake_features_np = np.concatenate(fake_features)\n",
        "\n",
        "real_features = extract_features(real_features_np, resnet_model)\n",
        "fake_features = extract_features(fake_features_np, resnet_model)\n",
        "\n",
        "fid_value = calculate_fid(real_features, fake_features)\n",
        "all_fid = [fid_value] * len(results)\n",
        "\n",
        "# Add FID to results\n",
        "results = [result + [fid_value] for result in results]\n",
        "\n",
        "# Calculate average metrics\n",
        "average_metrics = np.mean(results, axis=0)\n",
        "print(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}, FID={average_metrics[3]:.4f}\")\n",
        "\n",
        "# Plotting Metrics\n",
        "def plot_metric(metric_values, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(metric_values, label=metric_name)\n",
        "    plt.xlabel(\"Image Index\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f\"{metric_name} Across Validation Images\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Separate plots for each metric\n",
        "plot_metric(all_mse, \"MSE\")\n",
        "plot_metric(all_psnr, \"PSNR (dB)\")\n",
        "plot_metric(all_ssim, \"SSIM\")\n",
        "plot_metric([fid_value] * len(all_mse), \"FID\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T18:45:10.082228Z",
          "iopub.execute_input": "2024-12-09T18:45:10.082517Z",
          "iopub.status.idle": "2024-12-09T18:46:26.347619Z",
          "shell.execute_reply.started": "2024-12-09T18:45:10.082488Z",
          "shell.execute_reply": "2024-12-09T18:46:26.346571Z"
        },
        "id": "K92PuRiQsDOs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "72WMMvwpsDOs"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}