{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom skimage.metrics import structural_similarity as ssim\nimport cv2\nimport os\nimport re\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# Define constants\nSIZE = 160\nBATCH_SIZE = 50\nEPOCHS = 50\n\n# Helper function for alphanumeric sorting\ndef sorted_alphanumeric(data):\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(data, key=alphanum_key)\n\n# Load and preprocess images\ndef load_images(color_path):\n    color_img = []\n    gray_img = []\n\n    color_files = os.listdir(color_path)\n    color_files = sorted_alphanumeric(color_files)\n\n    for file_name in tqdm(color_files):\n        color_image = cv2.imread(os.path.join(color_path, file_name), 1)\n\n        if color_image is None:\n            continue\n\n        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n        color_image = cv2.resize(color_image, (SIZE, SIZE))\n        color_image = color_image.astype('float32') / 255.0\n        color_img.append(img_to_array(color_image))\n\n        gray_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2GRAY)\n        gray_image = np.expand_dims(gray_image, axis=-1)\n        gray_img.append(img_to_array(gray_image))\n\n    return np.array(color_img), np.array(gray_img)\n\ncolor_path = '/kaggle/input/imagenetsubsub'  # Update to your dataset path\ncolor_img, gray_img = load_images(color_path)\n\n# Split data into training and testing\ntrain_color_image, train_gray_image = color_img[:3000], gray_img[:3000]\ntest_color_image, test_gray_image = color_img[3000:], gray_img[3000:]\n\ntrain_g = np.repeat(train_gray_image, 3, axis=-1)\ntest_g = np.repeat(test_gray_image, 3, axis=-1)\n\nprint('Train gray image shape:', train_g.shape)\nprint('Train color image shape:', train_color_image.shape)\nprint('Test gray image shape:', test_g.shape)\nprint('Test color image shape:', test_color_image.shape)\n\n# Define the model\ndef down(filters, kernel_size, apply_batch_normalization=True):\n    downsample = Sequential()\n    downsample.add(layers.Conv2D(filters, kernel_size, padding='same', strides=2))\n    if apply_batch_normalization:\n        downsample.add(layers.BatchNormalization())\n    downsample.add(layers.LeakyReLU())\n    return downsample\n\ndef up(filters, kernel_size, dropout=False):\n    upsample = Sequential()\n    upsample.add(layers.Conv2DTranspose(filters, kernel_size, padding='same', strides=2))\n    if dropout:\n        upsample.add(layers.Dropout(0.2))\n    upsample.add(layers.LeakyReLU())\n    return upsample\n\ndef build_generator():\n    inputs = layers.Input(shape=[SIZE, SIZE, 3])\n    d1 = down(128, (3, 3), False)(inputs)\n    d2 = down(128, (3, 3), False)(d1)\n    d3 = down(256, (3, 3), True)(d2)\n    d4 = down(512, (3, 3), True)(d3)\n    d5 = down(512, (3, 3), True)(d4)\n\n    u1 = up(512, (3, 3), False)(d5)\n    u1 = layers.concatenate([u1, d4])\n    u2 = up(256, (3, 3), False)(u1)\n    u2 = layers.concatenate([u2, d3])\n    u3 = up(128, (3, 3), False)(u2)\n    u3 = layers.concatenate([u3, d2])\n    u4 = up(128, (3, 3), False)(u3)\n    u4 = layers.concatenate([u4, d1])\n    u5 = up(3, (3, 3), False)(u4)\n    output = layers.Conv2D(3, (2, 2), strides=1, padding='same', activation='tanh')(u5)\n\n    return Model(inputs, output)\n\ndef build_discriminator():\n    inputs = layers.Input(shape=(SIZE, SIZE, 6))\n    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n    x = layers.LeakyReLU()(x)\n    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    x = layers.Conv2D(256, (4, 4), strides=2, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    x = layers.Conv2D(512, (4, 4), strides=2, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(1, activation='sigmoid')(x)\n    return Model(inputs, x)\n\nvgg = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\nfeature_extractor = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\nfeature_extractor.trainable = False\n\ndef perceptual_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true, (-1, SIZE, SIZE, 3))\n    y_pred = tf.reshape(y_pred, (-1, SIZE, SIZE, 3))\n    y_true *= 255.0\n    y_pred *= 255.0\n    y_true_features = feature_extractor(y_true)\n    y_pred_features = feature_extractor(y_pred)\n    return tf.reduce_mean(tf.square(y_true_features - y_pred_features))\n\n# Build models\ngenerator = build_generator()\ndiscriminator = build_discriminator()\n\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\n\ngray_input = layers.Input(shape=(SIZE, SIZE, 3))\ncolor_output = generator(gray_input)\ncombined_input = layers.Concatenate()([gray_input, color_output])\nvalidity = discriminator(combined_input)\ncombined = Model(gray_input, validity)\ncombined.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n                 loss=perceptual_loss)\n\n# Training\nreal = np.ones((BATCH_SIZE, 1))\nfake = np.zeros((BATCH_SIZE, 1))\n\nfor epoch in range(EPOCHS):\n    for batch in range(0, len(train_g), BATCH_SIZE):\n        gray_batch = train_g[batch:batch + BATCH_SIZE]\n        color_batch = train_color_image[batch:batch + BATCH_SIZE]\n\n        if gray_batch.shape[0] < BATCH_SIZE:\n            continue\n\n        fake_color_batch = generator.predict(gray_batch)\n        real_combined = np.concatenate([gray_batch, color_batch], axis=-1)\n        fake_combined = np.concatenate([gray_batch, fake_color_batch], axis=-1)\n\n        d_loss_real = discriminator.train_on_batch(real_combined, real)\n        d_loss_fake = discriminator.train_on_batch(fake_combined, fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        g_loss = combined.train_on_batch(gray_batch, color_batch)\n\n    print(f\"Epoch {epoch + 1}/{EPOCHS}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n\n# Evaluation and plotting\ndef calculate_metrics(color, predicted):\n    mse = np.mean((color - predicted) ** 2)\n    psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n    ssim_value = ssim(color, predicted, multichannel=True, data_range=color.max() - color.min())\n    return mse, psnr, ssim_value\n\ndef plot_images_with_metrics(color, grayscale, predicted, mse, psnr, ssim_value):\n    plt.figure(figsize=(15, 15))\n    plt.subplot(1, 3, 1)\n    plt.title('Color Image', color='green', fontsize=20)\n    plt.imshow(color)\n    plt.subplot(1, 3, 2)\n    plt.title('Grayscale Image', color='black', fontsize=20)\n    plt.imshow(grayscale, cmap='gray')\n    plt.subplot(1, 3, 3)\n    plt.title(f'Predicted Image\\nMSE: {mse:.4f}\\nPSNR: {psnr:.2f} dB\\nSSIM: {ssim_value:.4f}', color='red', fontsize=16)\n    plt.imshow(predicted)\n    plt.show()\n\nresults = []\nfor i in range(50, 58):\n    gray_image = np.repeat(test_gray_image[i], 3, axis=-1)\n    gray_image = gray_image.reshape(1, SIZE, SIZE, 3)\n    predicted = generator.predict(gray_image)\n    predicted = predicted.squeeze()\n    predicted = np.clip(predicted, 0.0, 1.0)\n    mse, psnr, ssim_value = calculate_metrics(test_color_image[i], predicted)\n    results.append([mse, psnr, ssim_value])\n    plot_images_with_metrics(test_color_image[i], test_gray_image[i].squeeze(), predicted, mse, psnr, ssim_value)\n\naverage_metrics = np.mean(results, axis=0)\nprint(f\"Average Metrics: MSE={average_metrics[0]:.4f}, PSNR={average_metrics[1]:.2f} dB, SSIM={average_metrics[2]:.4f}\")\n","metadata":{"_uuid":"9891a1d1-4a82-4945-8c3f-9fb7883209fe","_cell_guid":"944632db-e7a1-4953-ab20-2606742168ba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}