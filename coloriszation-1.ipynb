{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10121862,"sourceType":"datasetVersion","datasetId":6245757},{"sourceId":190849,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":162676,"modelId":185027}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport os\nimport cv2\nimport numpy as np\nfrom math import log10, sqrt\n\n# Paths (adjust as needed)\ninput_dir = '/kaggle/input/imagenetsubsub'   # directory with original colored images\ngray_dir = '/kaggle/working/gray_images/'     # directory to store grayscale images\ncolorized_dir = '/kaggle/working/colorized_images/' # directory to store colorized images\n\n# Ensure output directories exist\nos.makedirs(gray_dir, exist_ok=True)\nos.makedirs(colorized_dir, exist_ok=True)\n\n# Paths to model files (place them in a known location)\nprototxt_path = '/kaggle/input/newmodelimagecolor/other/default/1/colorization_deploy_v2.prototxt'\ncaffemodel_path = '/kaggle/input/newmodelimagecolor/other/default/1/colorization_release_v2.caffemodel'\npts_in_hull_path = '/kaggle/input/newmodelimagecolor/other/default/1/pts_in_hull.npy'\n\n# Load the cluster centers\npts_in_hull = np.load(pts_in_hull_path)\n \n# Load the pre-trained model\nnet = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n\n# Populate the cluster centers as 1x1 convolution kernel\nclass8 = net.getLayerId(\"class8_ab\")\nconv8 = net.getLayerId(\"conv8_313_rh\")\npts = pts_in_hull.transpose().reshape(2, 313, 1, 1)\nnet.getLayer(class8).blobs = [pts.astype(np.float32)]\nnet.getLayer(conv8).blobs = [np.full([1,313], 2.606, np.float32)] # This is the default scale factor from the authors\n\ndef convert_to_grayscale_and_save(image_path, save_path):\n    img = cv2.imread(image_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # Convert single-channel grayscale to 3-channel grayscale for consistency\n    gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n    cv2.imwrite(save_path, gray_3ch)\n    return img, gray_3ch\n\ndef colorize_image(gray_img):\n    # Convert grayscale image (BGR) to Lab\n    img_lab = cv2.cvtColor(gray_img, cv2.COLOR_BGR2LAB)\n    L_channel = img_lab[:, :, 0].astype(\"float32\") / 255.0\n\n    # Create the input blob from L channel\n    blob = cv2.dnn.blobFromImage(L_channel)  # shape (1,1,H,W)\n    net.setInput(blob)\n\n    # Forward pass through the network\n    # Only get the 'class8_ab' output layer\n    ab_dec = net.forward('class8_ab')[0, :, :, :]  # shape: (2, h', w')\n    # Transpose to make it (h', w', 2)\n    ab_dec = ab_dec.transpose((1, 2, 0))\n\n    # Resize the predicted ab map to the size of the original image\n    h, w, _ = gray_img.shape\n    ab_dec = cv2.resize(ab_dec, (w, h))\n\n    # Recombine L with ab\n    L = L_channel * 100  # Lab L channel scale [0,100]\n    a = ab_dec[:, :, 0] * 128\n    b = ab_dec[:, :, 1] * 128\n\n    color_lab = np.zeros((h, w, 3), dtype=np.float32)\n    color_lab[:, :, 0] = L\n    color_lab[:, :, 1] = a\n    color_lab[:, :, 2] = b\n\n    # Convert LAB back to BGR\n    color_bgr = cv2.cvtColor(color_lab, cv2.COLOR_Lab2BGR)\n    color_bgr = np.clip(color_bgr, 0, 255).astype(\"uint8\")\n\n    return color_bgr\n\n\n\ndef mse(img1, img2):\n    # Mean Squared Error between two images\n    err = np.mean((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n    return err\n\ndef psnr(img1, img2):\n    # Peak Signal-to-Noise Ratio\n    # First compute the MSE\n    m = mse(img1, img2)\n    if m == 0:\n        return 100\n    return 10 * log10((255**2) / m)\n\n# Collect all images from the input directory\nimage_paths = glob.glob(os.path.join(input_dir, '*.*'))\n \npsnr_values = []\n\nfor img_path in image_paths:\n    filename = os.path.basename(img_path)\n    gray_path = os.path.join(gray_dir, filename)\n    colorized_path = os.path.join(colorized_dir, filename)\n    \n    # Convert to grayscale and save\n    original, gray_img = convert_to_grayscale_and_save(img_path, gray_path)\n    \n    # Colorize using the pre-trained model\n    colorized_img = colorize_image(gray_img)\n    cv2.imwrite(colorized_path, colorized_img)\n    \n    # Calculate a metric (e.g., PSNR) to evaluate \"accuracy\"\n    current_psnr = psnr(original, colorized_img)\n    psnr_values.append(current_psnr)\n\n# Compute average PSNR across all images\navg_psnr = np.mean(psnr_values)\nprint(\"Average PSNR across all colorized images:\", avg_psnr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:23:02.730753Z","iopub.execute_input":"2024-12-06T18:23:02.731569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install net","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:26:41.278211Z","iopub.execute_input":"2024-12-06T18:26:41.278555Z","iopub.status.idle":"2024-12-06T18:26:50.911743Z","shell.execute_reply.started":"2024-12-06T18:26:41.278523Z","shell.execute_reply":"2024-12-06T18:26:50.910605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_images(original, grayscale, colorized):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.title(\"Original\")\n    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n    plt.axis(\"off\")\n\n    plt.subplot(1, 3, 2)\n    plt.title(\"Grayscale\")\n    plt.imshow(cv2.cvtColor(grayscale, cv2.COLOR_BGR2RGB))\n    plt.axis(\"off\")\n\n    plt.subplot(1, 3, 3)\n    plt.title(\"Colorized\")\n    plt.imshow(cv2.cvtColor(colorized, cv2.COLOR_BGR2RGB))\n    plt.axis(\"off\")\n\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:45:05.779946Z","iopub.execute_input":"2024-12-06T18:45:05.780268Z","iopub.status.idle":"2024-12-06T18:45:05.814575Z","shell.execute_reply.started":"2024-12-06T18:45:05.780237Z","shell.execute_reply":"2024-12-06T18:45:05.813805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport os\nimport cv2\nimport numpy as np\nfrom math import log10, sqrt\n\n# Input and output paths\ninput_dir = '/kaggle/input/imagenetsubsub/'\ngray_dir = '/kaggle/working/gray_images/'\ncolorized_dir = '/kaggle/working/colorized_images/'\n\nos.makedirs(gray_dir, exist_ok=True)\nos.makedirs(colorized_dir, exist_ok=True)\n\n# Paths to model files (adjust if placed elsewhere)\nprototxt_path = '/kaggle/input/newmodelimagecolor/other/default/1/colorization_deploy_v2.prototxt'\ncaffemodel_path = '/kaggle/input/newmodelimagecolor/other/default/1/colorization_release_v2.caffemodel'\npts_in_hull_path = '/kaggle/input/newmodelimagecolor/other/default/1/pts_in_hull.npy'\n\n# Constants based on the model's requirements\nW_in = 224\nH_in = 224\n\n# Load cluster centers\npts_in_hull = np.load(pts_in_hull_path)\n\n# Load the pre-trained model\nnet = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n\n# Populate cluster centers as layer blobs\nclass8 = net.getLayerId(\"class8_ab\")\nconv8 = net.getLayerId(\"conv8_313_rh\")\npts = pts_in_hull.transpose().reshape(2, 313, 1, 1)\nnet.getLayer(class8).blobs = [pts.astype(np.float32)]\nnet.getLayer(conv8).blobs = [np.full([1,313], 2.606, np.float32)]\n\n# Attempt to use GPU (comment out if CUDA not available)\ntry:\n    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n    print(\"Using CUDA backend and target for DNN.\")\nexcept:\n    print(\"CUDA not available, using default backend.\")\n\ndef convert_to_grayscale_and_save(image_path, save_path):\n    img = cv2.imread(image_path)\n    if img is None:\n        return None, None\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n    cv2.imwrite(save_path, gray_3ch)\n    return img, gray_3ch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:45:05.816211Z","iopub.execute_input":"2024-12-06T18:45:05.816615Z","iopub.status.idle":"2024-12-06T18:45:08.496180Z","shell.execute_reply.started":"2024-12-06T18:45:05.816572Z","shell.execute_reply":"2024-12-06T18:45:08.495144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def colorize_image(gray_img):\n    # Convert BGR to Lab\n    img_lab = cv2.cvtColor(gray_img, cv2.COLOR_BGR2Lab)\n    img_l = img_lab[:, :, 0]  # Extract L channel\n\n    # Resize L channel to model's input size and subtract 50 for mean-centering\n    img_l_rs = cv2.resize(img_l, (W_in, H_in)).astype(np.float32) - 50.0\n    print(\"Shape of img_l_rs:\", img_l_rs.shape, \"Data type:\", img_l_rs.dtype)\n\n    # Create blob and set as input to the network\n    blob = cv2.dnn.blobFromImage(img_l_rs)\n    net.setInput(blob)\n\n    # Forward pass to predict 'ab' channels\n    ab_dec = net.forward()[0, :, :, :]\n    ab_dec = ab_dec.transpose((1, 2, 0))  # (H, W, 2)\n    print(\"Shape of ab_dec:\", ab_dec.shape, \"Min:\", ab_dec.min(), \"Max:\", ab_dec.max())\n\n    # Normalize and clip predicted 'ab' channels to [-1, 1]\n    ab_dec = np.clip(ab_dec, -1.0, 1.0)\n\n    # Resize predicted 'ab' to original image size\n    h, w = gray_img.shape[:2]\n    ab_dec_us = cv2.resize(ab_dec, (w, h))\n    print(\"Shape of ab_dec_us:\", ab_dec_us.shape)\n\n    # Reconstruct the Lab image\n    lab_out = np.zeros((h, w, 3), dtype=np.float32)\n    lab_out[:, :, 0] = img_l * (100.0 / 255.0)  # Scale L to [0, 100]\n    lab_out[:, :, 1:] = ab_dec_us * 128  # Scale back 'ab' channels\n\n    # Force valid range\n    lab_out[:, :, 0] = np.clip(lab_out[:, :, 0], 0, 100)  # Ensure L-channel is in [0, 100]\n    lab_out[:, :, 1:] = np.clip(lab_out[:, :, 1:], -128, 127)  # Ensure a/b channels are in [-128, 127]\n\n    # Convert to uint8 for OpenCV compatibility\n    lab_out_uint8 = np.clip(lab_out, 0, 255).astype(np.uint8)\n\n    # Debug: Visualize the Lab channels\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.title(\"L-channel\")\n    plt.imshow(lab_out[:, :, 0], cmap='gray')\n    plt.colorbar()\n\n    plt.subplot(1, 3, 2)\n    plt.title(\"a-channel\")\n    plt.imshow(lab_out[:, :, 1], cmap='jet')\n    plt.colorbar()\n\n    plt.subplot(1, 3, 3)\n    plt.title(\"b-channel\")\n    plt.imshow(lab_out[:, :, 2], cmap='jet')\n    plt.colorbar()\n\n    plt.show()\n\n    # Convert Lab back to BGR\n    bgr_out = cv2.cvtColor(lab_out_uint8, cv2.COLOR_Lab2BGR)\n    bgr_out = np.clip(bgr_out, 0, 255).astype(np.uint8)\n    return bgr_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:49:34.379645Z","iopub.execute_input":"2024-12-06T18:49:34.380329Z","iopub.status.idle":"2024-12-06T18:49:34.395107Z","shell.execute_reply.started":"2024-12-06T18:49:34.380275Z","shell.execute_reply":"2024-12-06T18:49:34.394126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mse(img1, img2):\n    err = np.mean((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n    return err\n\ndef psnr(img1, img2):\n    m = mse(img1, img2)\n    if m == 0:\n        return 100\n    return 10 * log10((255**2) / m)\n\nimage_paths = glob.glob(os.path.join(input_dir, '*.*'))\nimage_paths = image_paths[:100]  # Limit to 100 images\n\npsnr_values = []\n\nfor img_path in image_paths:\n    filename = os.path.basename(img_path)\n    gray_path = os.path.join(gray_dir, filename)\n    colorized_path = os.path.join(colorized_dir, filename)\n\n    original, gray_img = convert_to_grayscale_and_save(img_path, gray_path)\n    \n    # If reading the image failed, continue\n    if original is None or gray_img is None:\n        continue\n\n    colorized_img = colorize_image(gray_img)\n    cv2.imwrite(colorized_path, colorized_img)\n\n    current_psnr = psnr(original, colorized_img)\n    psnr_values.append(current_psnr)\n    visualize_images(original, gray_img, colorized_img)\n\n\navg_psnr = np.mean(psnr_values) if psnr_values else 0\nprint(\"Average PSNR across all colorized images:\", avg_psnr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:49:34.396104Z","iopub.execute_input":"2024-12-06T18:49:34.396384Z","iopub.status.idle":"2024-12-06T18:52:21.620518Z","shell.execute_reply.started":"2024-12-06T18:49:34.396355Z","shell.execute_reply":"2024-12-06T18:52:21.619497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:34:47.162131Z","iopub.status.idle":"2024-12-06T18:34:47.162425Z","shell.execute_reply.started":"2024-12-06T18:34:47.162283Z","shell.execute_reply":"2024-12-06T18:34:47.162299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}